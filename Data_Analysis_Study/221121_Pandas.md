> 부트캠프 6주차 2022년 11월 21일

## Pandas

### 7. 기술 통계 계산과 요약

**7.1 상관관계와 공분산**

[→ 공분산과 상관계수](https://datalabbit.tistory.com/15)

```python
df = pd.DataFrame({"math" : [50, 60, 40, 30, 70, 50], "physics" : [40, 60, 50, 20, 80, 50]})
df
```

![image](https://user-images.githubusercontent.com/106129152/202997867-01edda37-3591-4d00-9401-3cfc1fd1645a.png)

- **산포도(산점도)**
    
    ```python
    df.plot(kind="scatter", x="math", y="physics") # 기본형 : 선그래프
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202997893-8f0b1487-849e-488a-8b68-2574e9079137.png)
    
- **상관계수**
    
    ```python
    df.corr()
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202997926-7b412610-c99a-4416-9205-c019b7076040.png)
    

**7.2 범주 데이터 요약**

```python
titanic.describe()
```

![image](https://user-images.githubusercontent.com/106129152/202997972-3219c8e8-43ef-42a0-af51-096a2ec153f6.png)

```python
titanic.describe(include='object')
```

![image](https://user-images.githubusercontent.com/106129152/202998183-bfa4fbb6-3c12-4633-b84b-0a09d2e0cfd5.png)

```python
titanic["embarked"].unique() # unique한 원소들
# array(['S', 'C', 'Q', nan], dtype=object)

titanic["embarked"].nunique() # unique한 원소들의 갯수
# 3

# 아래는 pd.value_counts(titanic["embarked"]) 와 동일
titanic["embarked"].value_counts() # 고유값(unique한 원소들)의 빈도수(건수)
# S    644
# C    168
# Q     77
# Name: embarked, dtype: int64

titanic["embarked"].hist()
```

![image](https://user-images.githubusercontent.com/106129152/202998282-64b6f977-52c2-48b5-9382-37d5743d0fdc.png)

### 8. 데이터 로딩과 저장

→ [Pandas csv 파일 사용법](https://bigdaheta.tistory.com/40)

- **데이터 로딩**
    
    ```python
    # read_csv
    df = pd.read_csv('./examples/ex1.csv')
    
    # read_table
    df = pd.read_table('./examples/ex1.csv', sep=',')
    ```
    
    위의 코드 2개는 동일한 결과가 나온다. 
    
    read_csv를 사용해도 되고, read_table의 sep 값에 ‘,’를 넣어줘도 된다.
    
    컬럼이 없는 데이터를 불러올 때,
    
    아래처럼 header = None으로 설정하거나
    
    names에 컬럼값을 넣어줘도 된다.
    
    ```python
    # header=None
    df = pd.read_csv('./examples/ex2.csv', header=None)
    
    # names
    names = ['a', 'b', 'c', 'd', 'message']
    df = pd.read_csv('./examples/ex2.csv', names=names)
    ```
    
    특정 컬럼을 인덱스로 설정할 수도 있다.
    
    ```python
    # set_index
    df.set_index('message')
    
    # index_col='컬럼명'
    names = ['a', 'b', 'c', 'd', 'message']
    df = pd.read_csv('./examples/ex2.csv', names=names, index_col='message')
    
    # index_col='컬럼 순서'
    names = ['a', 'b', 'c', 'd', 'message']
    df = pd.read_csv('./examples/ex2.csv', names=names, index_col=4)
    ```
    
    데이터가 콤마로 나뉘어져있지 않은 txt파일은 어떻게 읽을까?
    
    일단 공백으로 나뉘어져있는 데이터라면 아래와 같은 방법으로도 가능하다.
    
    ```python
    # 공백 1개 이상의 패턴과 매치시킨다
    df = pd.read_table('./examples/ex3.txt', sep='\s+')
    ```
    
- **데이터 저장**
    
    to_csv 를 사용해서 데이터를 저장할 수도 있다.
    
    ```python
    # 자동으로 부여된 인덱스까지도 전부 저장됨
    df.to_csv('./examples/out.csv') 
    
    # 위와 같은 문제 발생시 아래처럼 index값을 False로 지정해주면 됨
    df.to_csv('./examples/out.csv', index=False)
    ```
    

### 9.데이터 정제 및 준비

**9.1 누락된 데이터 처리하기**

- **결측치 골라내기**
    
    ```python
    string_data = pd.Series(['abc', 'def', np.nan, 'ghi'])
    # 0    abc
    # 1    def
    # 2    NaN
    # 3    ghi
    # dtype: object
    ```
    
    isnull()을 사용하면 결측데이터를 찾아낼 수 있다.
    
    ```python
    pd.isnull(string_data) # string_data.isnull()
    # 0    False
    # 1    False
    # 2     True
    # 3    False
    # dtype: bool
    ```
    
    여기서, np.nan 대신 파이썬의 None을 넣어도 null로 인식한다.
    
    불리안 색인도 가능하다.
    
    ```python
    data = pd.Series([1, np.nan, 3.5, np.nan, 7])
    data
    # 0    1.0
    # 1    NaN
    # 2    3.5
    # 3    NaN
    # 4    7.0
    # dtype: float64
    
    data[data.isnull()] # 불리안 색인
    # 1   NaN
    # 3   NaN
    # dtype: float64
    ```
    
    Null인 행을 삭제하고 싶다면 Null인 행의 인덱스를 구하고, 
    
    drop 함수에 적용할 수 있지만,
    
    dropna를 사용하면 null인 행을 손쉽게 삭제할 수 있다.
    
    ```python
    data.dropna()
    # 0    1.0
    # 2    3.5
    # 4    7.0
    # dtype: float64
    ```
    
    그렇다면 2차원 데이터인 DataFrame에는 어떻게 적용될까?
    
    ```python
    data = pd.DataFrame([[1.0, 6.5, 3.0],
                         [1.0, np.nan, np.nan],
                         [np.nan, np.nan, np.nan],
                         [np.nan, 6.0, 3.0]])
    data
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202998365-7b1f3c1e-e447-407f-a6c4-c2977fdb410a.png)
    
    위와 같은 DataFrame이 있을 때, dropna를 쓰면 다음과 같이 된다.
    
    ```python
    data.dropna() # axis=0으로 설정되어 있으므로 행을 삭제
                  # how='any' 가 디폴트값이므로 null이 하나라도 있으면 삭제
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202998391-92e27f17-3115-4443-bbd1-d8ad84d7192c.png)
    
    ```python
    data.dropna(how='all') # 행을 삭제하되, 그 행의 모든 값이 Null인 행만 삭제
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202998635-b5f2b516-0f99-4e20-b7eb-a99bf578648e.png)
    
    아래와 같은 DataFrame이 있을 때, 
    
    ![image](https://user-images.githubusercontent.com/106129152/202998660-75b308b5-bf77-4e4c-a06d-956fc1c415ef.png)
    
    thresh=5 : null이 아닌 데이터가 5개보다 미만인 데이터만 삭제 가능
    
    ```python
    df.dropna(axis=1, thresh=5)
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202998708-7e47ecd5-cdf4-42ba-ae48-d9620be9d49b.png)
    
- **결측치 채우기**
    
    아래의 DataFrame에 다양한 방법으로 결측치를 채워넣을 수 있다.
    
    ![image](https://user-images.githubusercontent.com/106129152/202998958-c7646795-9243-4718-8747-9237b776a230.png)
    
    ```python
    # NaN값을 0으로 채우기
    df.fillna(0)
    
    # 행과 열을 지정해서 값을 채워넣기
    df.fillna({1:0, 2:0.5})
    
    # axis=0이므로 "행축을 따라서" 바로 앞의 값으로 채워넣기
    df.fillna(axis=0, method='ffill') 
    
    # limit으로 채워넣을 갯수에 제한을 걸 수도 있음
    df.fillna(axis=0, method='ffill', limit=2)
    ```
    
    당연하게도 원본에 반영되는 것이 아니라,
    
    원본에 반영하고 싶다면 inplace=True로 설정해주면 된다.
    
    직접 구한 값으로 넣을 수도 있다.
    
    ```python
    m = df.mean(axis=0).mean()
    df.fillna(m) # 0.326647
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999005-28b1513f-3bff-47db-8739-e8f1f8cfafa8.png)
    

**9.2 데이터 변형**

- **중복 제거하기**
    
    ```python
    data = pd.DataFrame({'k1':['one', 'two']*3 + ['two'],
                  'k2':[1, 1, 2, 3, 3, 4, 4]})
    data
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999161-0361e9e6-e9d9-4894-9cfa-0d5f4afc4dfb.png)
    
    ```python
    # 중복인지 체크
    data.duplicated() # keep='first'가 디폴트
    # 0    False
    # 1    False
    # 2    False
    # 3    False
    # 4    False
    # 5    False
    # 6     True
    # dtype: bool
    
    data.duplicated(keep='last')
    # 0    False
    # 1    False
    # 2    False
    # 3    False
    # 4    False
    # 5     True
    # 6    False
    # dtype: bool
    
    # 중복인지 체크(k1 컬럼 기준)
    data.duplicated(['k1'])
    # 0    False
    # 1    False
    # 2     True
    # 3     True
    # 4     True
    # 5     True
    # 6     True
    # dtype: bool
    ```
    
    ```python
    # 중복 삭제
    data.drop_duplicates() # 6번 행이 삭제되었음
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999320-f5d9e4ec-7381-4985-877a-8b68f44d16f8.png)
    
    ```python
    # k1 열 기준으로 중복값이 삭제됨
    data.drop_duplicates(['k1'])
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999360-eb789b5d-352a-4298-91d6-e6d259c43776.png)
    
    ```python
    data.drop_duplicates(['k1'], keep='last')
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999480-dd6c9aba-36fa-4dd7-b73b-11989d8910a5.png)
    
    컬럼 여러 개를 지정하고 싶으면 `data.drop_duplicates(['k1', 'k2'])` 와 같이 코드를 작성하면 된다.
    
- **값 치환하기**
    
    ```python
    data = pd.Series([1, -999, 2, -999, -1000, 3])
    data
    # 0       1
    # 1    -999
    # 2       2
    # 3    -999
    # 4   -1000
    # 5       3
    # dtype: int64
    ```
    
    ```python
    # replace(old, new)
    
    data.replace(-999, np.nan)
    # 0       1.0
    # 1       NaN
    # 2       2.0
    # 3       NaN
    # 4   -1000.0
    # 5       3.0
    # dtype: float64
    
    data.replace([-999, -1000], np.nan)
    # 0    1.0
    # 1    NaN
    # 2    2.0
    # 3    NaN
    # 4    NaN
    # 5    3.0
    # dtype: float64
    
    # data.replace({-999:np.nan, -1000:0})와 동일
    data.replace([-999, -1000], [np.nan, 0])
    # 0    1.0
    # 1    NaN
    # 2    2.0
    # 3    NaN
    # 4    0.0
    # 5    3.0
    # dtype: float64
    ```
    
- **축 색인 이름 바꾸기**
    
    ```python
    data = pd.DataFrame(np.arange(12).reshape(3, 4),
                         index=['Ohio', 'Colorado', 'New York'],
                         columns=['one', 'two', 'three', 'four'])
    data
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999767-4237677f-59ca-4923-b95d-1d5b7e4e4315.png)
    
    ```python
    # 함수 적용
    
    # def upper_tx(x):
    #     return x.upper()
    
    # upper_tx = lambda x:x.upper()
    # data.index.map(upper_tx)
    
    data.index.map(lambda x:x.upper())
    # Index(['OHIO', 'COLORADO', 'NEW YORK'], dtype='object')
    ```
    
    일괄 수정이 아닌 개별 수정이 하고 싶을 때 rename을 사용하면 된다.
    
    ```python
    data.rename(index={'Ohio':'Indiana'})
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999793-02e7d53f-797a-41da-aae4-0b0309d89d13.png)
    
    이런 식으로 내장함수도 적용할 수 있다.
    
    ```python
    data.rename(index=str.lower, columns=str.title)
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/202999813-44a3c279-5378-45b0-9980-dd85da976fcf.png)
    

- **벡터화된 문자열 함수**
    
    ```python
    data = {'Dave':'dave@gmail.com',
            'Steve': 'steve@gmail.com',
            'Rob':'rob@gmail.com',
            'Wes':np.nan,
            'Puppy':'p',
            'Number':'123'}
    sr_data= pd.Series(data)
    sr_data
    # Dave       dave@gmail.com
    # Steve     steve@gmail.com
    # Rob         rob@gmail.com
    # Wes                   NaN
    # Puppy                   p
    # Number                123
    # dtype: object
    ```
    
    ```python
    sr_data.str.isnumeric() # 숫자인 값 : True
    # Dave      False
    # Steve     False
    # Rob       False
    # Wes         NaN
    # Puppy     False
    # Number     True
    # dtype: object
    
    sr_data.str.isalpha() # 문자인 값 : True
    # Dave      False
    # Steve     False
    # Rob       False
    # Wes         NaN
    # Puppy      True
    # Number    False
    # dtype: object
    
    sr_data.str.contains('gmail') # 문자열 포함 확인
    # Dave       True
    # Steve      True
    # Rob        True
    # Wes         NaN
    # Puppy     False
    # Number    False
    # dtype: object
    ```
    
    → 여기서, `sr_data.str.isalpha()`를 썼을 때 메일 주소가 담긴 행이 False가 뜨는 이유는, 공백, 특수문자, 숫자 중 포함된 것이 있기 때문이다. (해당 코드에서는 ‘@’라는 특수문자가 포함되어 있기 때문에 False 반환)
    

- **데이터 구간 분할**
    
    수치데이터(양적데이터) → 범주형데이터(질적데이터)
    
    ```python
    ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]
    ages
    # [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]
    ```
    
    ```python
    bins = [18, 25, 35, 60, 100]
    cats = pd.cut(ages, bins)
    cats
    # [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]
    # Length: 12
    # Categories (4, interval[int64, right]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]
    
    type(cats)
    # pandas.core.arrays.categorical.Categorical
    
    pd.value_counts(cats)
    # (18, 25]     5
    # (25, 35]     3
    # (35, 60]     3
    # (60, 100]    1
    # dtype: int64
    ```
    
    위와 같이 데이터를 구간별로 분할할 수 있다. 
    
    또, 구간별로 이름을 정할 수도 있다.
    
    ```python
    bins = [18, 25, 35, 60, 100]
    cats = pd.cut(ages, bins, labels=["Youth", "YoungAdult", "MidleAged", "Senior"])
    cats
    # ['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', 'MidleAged', 'MidleAged', 'YoungAdult']
    # Length: 12
    # Categories (4, object): ['Youth' < 'YoungAdult' < 'MidleAged' < 'Senior']
    
    pd.value_counts(cats)
    # Youth         5
    # YoungAdult    3
    # MidleAged     3
    # Senior        1
    # dtype: int64
    ```
    
    같은 갯수로 구간을 나누는 함수도 있다.
    
    ```python
    qcats = pd.qcut(ages, 4)
    pd.value_counts(qcats)
    # (19.999, 22.75]    3
    # (22.75, 29.0]      3
    # (29.0, 38.0]       3
    # (38.0, 61.0]       3
    # dtype: int64
    ```
    
- **특잇값(바깥값, outlier) 찾고 제외하기**
    
    ```python
    data = pd.DataFrame(np.random.randn(1000, 4))
    data.describe()
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/203000288-abc4d297-abfd-4eb3-b63f-39f1fdbccf64.png)
    
    위의 데이터에서 3보다 큰 값을 특잇값(바깥값, outlier)로 가정하고,
    
    해당 값을 3으로 치환해보자.
    
    ```python
    (data > 3).any(axis=1) # 열축을 따라서 True값이 하나라도 있는지 확인
    # 0      False
    # 1      False
    # 2      False
    # 3      False
    # 4      False
    #        ...  
    # 995    False
    # 996    False
    # 997    False
    # 998    False
    # 999    False
    # Length: 1000, dtype: bool
    
    (data > 3).any(axis=1).sum()
    # 7
    ```
    
    7건의 데이터를 확인해보면 아래와 같다.
    
    ```python
    data[(data > 3).any(axis=1)]
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/203000329-22740105-9be5-48fd-9525-edf0a6867ad2.png)
    
    이 3 이상의 값들을 3으로 치환하고 수정된 것을 확인해보자.
    
    ```python
    data[data>3] = 3
    
    data.describe() # max값이 3으로 수정된 것을 확인
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/203000363-927414b5-7223-4b93-84d4-09a1e9325f07.png)
    
- **더미변수 계산하기(one-hot encoding)**
    
    **더미(dummy)변수** : 가변수로서 독립변수를 0과1로 변환한 변수
    를 의미한다.
    
    ```python
    df = pd.DataFrame({'fruit':['apple', 'apple', 'pear', 'peach', 'pear'],
                  'data':range(5)})
    df
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/203000471-28123bdd-570d-4828-a977-b6115dfc91d5.png)
    
    ```python
    dummies = pd.get_dummies(df['fruit'], prefix='fruit')
    dummies
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/203001078-4d19110d-22a6-4733-9886-e8a3280091dd.png)
    
    ```python
    pd.concat([df[['data']], dummies], axis=1)
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/203001225-f332eb7b-a542-4be3-aa2c-416a812c6346.png)
    
    → [구간화, 더미변수](https://seeyapangpang.tistory.com/33)
    

