> 부트캠프 9주차 2022년 12월 15일

# OpenCV

```python
import cv2
import numpy as np
```

# 영상의 기하학적 변환

## 전단 변환

전단 변환은 가로 방향 또는 세로 방향으로 각각 정의할 수 있다.

픽셀이 어느 위치에 있는가에 따라 이동 정도가 달라진다.

```python
src = cv2.imread('./data/tekapo.bmp')

height = src.shape[0]
width = src.shape[1]

Mx = 0.8

M = np.array([[1, Mx, 0],
              [0, 1, 0]], dtype=np.float64)

dst = cv2.warpAffine(src, M, (int(width + Mx * height), height))

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207804935-459d2faf-b8ce-4205-9aff-3af10f522064.png)

## 크기 변환

```python
src = cv2.imread('./data/tekapo.bmp')

height = src.shape[0]
width = src.shape[1]

Sx = 1.2
Sy = 1.2

M = np.array([[Sx, 0, 0],
              [0, Sy, 0]], dtype=np.float64)

dst = cv2.warpAffine(src, M, (int(width * Sx), int(height * Sy)))

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207804980-383d9e6b-eec0-4b1f-896a-d792b2c2768e.png)

하지만 OpenCV에서는 크기 변환을 손쉽게 할 수 있는 **resize** 함수를 제공함!

```python
src = cv2.imread('./data/tekapo.bmp')

dst = cv2.resize(src, (0, 0), fx=1.2, fy=1.2)
# dst = cv2.resize(src, (1920, 1280)) 등 직접 사이즈 지정 가능

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

## 회전 변환

영상의 회전을 위한 어파인 변환 행렬을 생성하는 **getRotationMatrix2D** 함수를 제공

영상의 회전은 기본적으로 반시계 반향

```python
src = cv2.imread('./data/tekapo.bmp')

height = src.shape[0]
width = src.shape[1]

center = int(width/2), int(height/2)
angle = 20 # 반시계 방향 20도
scale = 1

M = cv2.getRotationMatrix2D(center, angle, scale)
dst = cv2.warpAffine(src, M, (0, 0))

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805031-8fc24007-1117-4afe-9a55-83b33783bc3f.png)

영상을 90도 단위로 회전시키고 싶을 때는 rotate 함수를 사용하면 된다.

```python
# 90도 단위로 회전할 때 rotate 함수를 사용
src = cv2.imread('./data/tekapo.bmp')

dst1 = cv2.rotate(src, cv2.ROTATE_90_CLOCKWISE)
dst2 = cv2.rotate(src, cv2.ROTATE_90_COUNTERCLOCKWISE) 

cv2.imshow('src', src)
cv2.imshow('dst1', dst1)
cv2.imshow('dst2', dst2)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805078-0b6e8453-b5a3-4055-8f7e-4aa93f1fee40.png)

## 대칭 변환

```python
src = cv2.imread('./data/tekapo.bmp')

dst = cv2.flip(src, 1) # flip code : 1(좌우 반전), 0(상하 반전), -1(좌우상하 모두 반전)

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805130-c51a54ce-5e2d-4d9d-a1d2-3a203c4f8cf0.png)

## 투시 변환

```python
src = cv2.imread('./data/tekapo.bmp')

height = src.shape[0]
width = src.shape[1]

src_pts = np.array([[0, 0], [width-1, 0], [width-1, height-1], [0, height-1]], np.float32)
dst_pts = np.array([[60, 100], [width-20, 80], [width-10, height-10], [5, height-20]], np.float32)

M = cv2.getPerspectiveTransform(src_pts, dst_pts)
dst = cv2.warpPerspective(src, M, (0, 0))

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805159-b9c75120-220e-471f-b359-c6c9df66f4c5.png)

```python
def on_mouse(event, x, y, flag, param):
    if event == cv2.EVENT_LBUTTONDOWN:
        src_pt_list.append([x, y])
        cv2.circle(src, (x, y), 5, (0, 0, 255), 5)
        cv2.imshow('src', src)
        if len(src_pt_list) == 4:
            src_pts = np.array(src_pt_list, dtype=np.float32)
            M = cv2.getPerspectiveTransform(src_pts, dst_pts)
            dst = cv2.warpPerspective(src, M, (width, height))
            cv2.imshow('dst', dst)
            
src_pt_list = []
width, hight = 200, 300
dst_pts = np.array([[0, 0], [width-1, 0], [width-1, height-1], [0, height-1]], np.float32) # 마우스로 클릭한 순서대로 결과에도 매칭
            
src = cv2.imread('./data/card.bmp')

cv2.imshow('src', src)
cv2.setMouseCallback('src', on_mouse)

cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805201-73ef4ef8-8ddd-486d-b5bb-69715ee90d65.png)

# 에지 검출과 응용

영상에서 에지(edge)는 한쪽 방향으로 픽셀 값이 급격하게 바뀌는 부분을 가리킨다.

에지를 찾아내는 것은 객체의 윤곽을 알아낼 수 있는 유용한 방법이다.

→ [[영상 처리] 에지 검출](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=bsw2428&logNo=221448393580)

## 마스크 기반 에지 검출 - 소벨 마스크

```python
src = cv2.imread('./data/lenna.bmp', cv2.IMREAD_GRAYSCALE)

Mx = np.array([[-1, 0, 1],
               [-2, 0, 2],
               [-1, 0, 1]], dtype=np.float32)
My = np.array([[-1, -2, -1],
               [0, 0, 0],
               [1, 2, 1]], dtype=np.float32)

dx = cv2.filter2D(src, -1, Mx)
dy = cv2.filter2D(src, -1, My)

cv2.imshow('src', src)
cv2.imshow('dx', dx)
cv2.imshow('dy', dy)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805230-adadfdff-256e-473d-8c7c-3ffb84ee284c.png)

`delta=128` 델타 값을 추가한 결과

![image](https://user-images.githubusercontent.com/106129152/207805265-bb2921ba-33bd-4a7e-8b6c-4b23c53c15de.png)

그러나 미분필터(소벨필터)를 따로 준비하지 않아도 원본 이미지와 마스크 연산까지 해주는 함수가 있다. 

```python
src = cv2.imread('./data/lenna.bmp', cv2.IMREAD_GRAYSCALE)

dx = cv2.Sobel(src, cv2.CV_32FC1, 1, 0) # x축으로 미분
dy = cv2.Sobel(src, cv2.CV_32FC1, 0, 1) # y축으로 미분

# cv2.Sobel() 함수는 cv2.filter2D()로 마스크 연산까지는 
# 동일한 형변환은 안되어 있고 포화연산도 안되어 있는 상태

fmag = cv2.magnitude(dx, dy) # x축으로 미분과 + y축으로의 미분 = 그래디언트
                            # magnitude가 그래디언트의 크기를 구함
mag = np.clip(fmag, 0, 255).astype(np.uint8)
T = 160
ret, dst = cv2.threshold(mag, T, 255, cv2.THRESH_BINARY)

cv2.imshow('src', src)
cv2.imshow('mag', mag)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805333-0e6832c1-1eea-40c2-9a41-5c2ebd22ba18.png)

## 캐니 에지 검출기

캐니 에지 검출기는 **가우시안 필터링 → 그래디언트 계산 → 비최대 억제 → 이중 임계값을 이용한 히스테리시스 에지 트래킹** 순으로 연산 과정을 거친다.

가우시안 필터링은 영상에 포함된 잡음을 제거하기 위한 것이다.

비최대 억제 과정은 에지가 두껍게 표현되는 현상을 방지하는 것.

이중 임계값을 사용하는 것은, 하나의 임계값을 사용할 경우 이분법으로 결과가 판단되어 환경 변화에 민감해질 수 있기 때문이다.

→ [Canny Edge 설명](https://com24everyday.tistory.com/370)

```python
src = cv2.imread('./data/lenna.bmp', cv2.IMREAD_GRAYSCALE)

dst = cv2.Canny(src, 80, 160) # low:high (1:2 or 1:3 Canny recomended)

cv2.imshow('src', src)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805375-6cd86a95-27ef-48ea-9567-620eb936a57e.png)

## 허프 변환 직선 검출

허프 변환은 2차원 x, y 좌표에서 직선의 방정식을 파라미터 공간으로 변환하여 직선을 찾는 알고리즘이다.

→ [허프 변환 : 직선 검출](https://velog.io/@redorangeyellowy/ch06-%EC%98%81%EC%83%81%EC%9D%98-%ED%8A%B9%EC%A7%95-%EC%B6%94%EC%B6%9C-%ED%97%88%ED%94%84-%EB%B3%80%ED%99%98-%EC%A7%81%EC%84%A0-%EA%B2%80%EC%B6%9C)

```python
import math

src = cv2.imread('./data/building.jpg', cv2.IMREAD_GRAYSCALE)

edge = cv2.Canny(src, 100, 200)

rho = 1 # or 2 : 숫자가 작을수록 더 정밀하게 검출
theta = math.pi/180 # 라디안 단위
threshold = 160 # 축적 배열의 숫자가 높다는 것은 직선을 이루는 점들이 많다는 뜻
                # 얼마나 큰 값을 직선으로 판단할지 threshold로 결정
minLineLength = 100 # 검출할 선분의 최소길이
maxLineGap = 5 # 직선으로 간주할 최대 에지 점 간격

lines = cv2.HoughLinesP(edge, rho, theta, threshold,
                       minLineLength = minLineLength,
                       maxLineGap = maxLineGap)
dst = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR) # 직선을 그릴 (3채널) 도화지

if lines is not None:
    for i in range(len(lines)):
        line = lines[i][0]
        pt1 = line[0], line[1]
        pt2 = line[2], line[3]
        cv2.line(dst, pt1, pt2, (0, 0, 255), 2, cv2.LINE_AA)

cv2.imshow('src', src)
cv2.imshow('edge', edge)
cv2.imshow('dst', dst)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image](https://user-images.githubusercontent.com/106129152/207805414-3da59039-2340-44b0-ae3d-b5df3f3ebaf9.png)
