> 부트캠프 12주차 2023년 1월 5일

# RetinaNet Train(BCCD)

## **1. Installation**

### **Step 1. Install MMCV using MIM.**

```python
!pip3 install openmim
!mim install mmcv-full
```

### **Step 2. Install MMDetection from the source.**

```python
!git clone https://github.com/open-mmlab/mmdetection.git
%cd mmdetection
!pip install -e .
```

### **Step 3. Verification**

```python
import mmdet
print(mmdet.__version__) # 2.27.0
```

### **Step 4. Inference**

github home에서 Overview of Benchmark and Model Zoo 섹션 확인

[https://github.com/open-mmlab/mmdetection/tree/master/configs/yolo](https://github.com/open-mmlab/mmdetection/tree/master/configs/yolo)

```python
!mim download mmdet --config yolov3_mobilenetv2_320_300e_coco --dest .

from mmdet.apis import init_detector, inference_detector

config_file = 'yolov3_mobilenetv2_320_300e_coco.py'
checkpoint_file = 'yolov3_mobilenetv2_320_300e_coco_20210719_215349-d18dff72.pth'
model = init_detector(config_file, checkpoint_file, device='cpu')  # or device='cuda:0'
inference_detector(model, 'demo/demo.jpg')
```

## 2. **Train A Detector on A Customized Dataset**

github의 demo 디렉토리 아래 [MMDet_Tutorial.ipynb](https://github.com/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb) 파일 참조

### **BCCD Dataset 다운로드**

[BCCD Dataset](https://github.com/Shenggan/BCCD_Dataset.git)

BCCD Dataset은 **백혈구(WBC), 적혈구(RBC), 혈소판(Platelets)** 세가지 유형의 Object Class.

다운로드 받은 Dataset은 Pascal VOC 형태이므로 이를 별도의 유틸리티를 이용하여 MS-COCO 형태로 변환

```python
# download the data
!git clone https://github.com/Shenggan/BCCD_Dataset.git
```

### **BCCD Dataset의 디렉토리 구조 보기**

```python
# Check the directory structure of the Oxford Pet

# Install tree first
!apt-get -q install tree

!tree ./BCCD_Dataset/BCCD
# ... 4 directories, 732 files
```

### **MS-COCO 포맷으로 변환하기**

voc 포맷을 coco 포맷으로 변환하는 패키지

[https://github.com/yukkyo/voc2coco](https://github.com/yukkyo/voc2coco) How to use 참고

```python
!git clone https://github.com/yukkyo/voc2coco.git
```

**1. Make labels.txt**

```python
with open('./BCCD_Dataset/BCCD/labels.txt', 'w') as f:
  f.write('WBC\n')
  f.write('RBC\n')
  f.write('Platelets\n')

!cat ./BCCD_Dataset/BCCD/labels.txt
# WBC
# RBC
# Platelets
```

**2. Run Script**

```python
%cd voc2coco
# /content/mmdetection/voc2coco

!python voc2coco.py --ann_dir ../BCCD_Dataset/BCCD/Annotations \
--ann_ids ../BCCD_Dataset/BCCD/ImageSets/Main/train.txt \
--labels ../BCCD_Dataset/BCCD/labels.txt \
--output ../BCCD_Dataset/BCCD/train.json \
--ext xml

!python voc2coco.py --ann_dir ../BCCD_Dataset/BCCD/Annotations \
--ann_ids ../BCCD_Dataset/BCCD/ImageSets/Main/val.txt \
--labels ../BCCD_Dataset/BCCD/labels.txt \
--output ../BCCD_Dataset/BCCD/val.json \
--ext xml

!python voc2coco.py --ann_dir ../BCCD_Dataset/BCCD/Annotations \
--ann_ids ../BCCD_Dataset/BCCD/ImageSets/Main/test.txt \
--labels ../BCCD_Dataset/BCCD/labels.txt \
--output ../BCCD_Dataset/BCCD/test.json \
--ext xml
```

### MS-COCO 포맷으로 변환된 json 파일 확인

```python
!cat ../BCCD_Dataset/BCCD/train.json 

# 온라인 파서 이용 http://json.parser.online.fr/
# 또는 jq 유틸리티 설치
!sudo apt-get install jq

!jq . ../BCCD_Dataset/BCCD/train.json > output.json
!tail -100 output.json
```

### **이미지와 레이블 보기**

```python
# voc2coco 디렉토리에서 상위로 이동하기 (mmdetection 폴더)
%cd ../
# /content/mmdetection
```

```python
# Let's take a look at the dataset image
import mmcv
import matplotlib.pyplot as plt

img = mmcv.imread('./BCCD_Dataset/BCCD/JPEGImages/BloodImage_00004.jpg')
plt.figure(figsize=(15, 10))
plt.imshow(mmcv.bgr2rgb(img))
plt.show()
```

![image](https://user-images.githubusercontent.com/106129152/210732800-ce4b96da-8d6e-4aeb-bc4f-b31cfe69c6fa.png)

```python
# Check the label of a single image
!cat ./BCCD_Dataset/BCCD/Annotations/BloodImage_00004.xml
```

```python
import os
import cv2
import matplotlib.pyplot as plt
import xml.etree.ElementTree as ET
img_dir = "./BCCD_Dataset/BCCD/JPEGImages"
xml_file = "./BCCD_Dataset/BCCD/Annotations/BloodImage_00004.xml"

class2color = {'WBC':(255, 255, 0), 'RBC':(255, 0, 255), 'Platelets':(0, 255, 255)}

tree = ET.parse(xml_file)
root = tree.getroot()

img_path = root.find('filename').text
img_full_path = os.path.join(img_dir, img_path)
img = cv2.imread(img_full_path)
dst = img.copy()

objects = root.findall('object')
object_list = []

for obj in objects:
  box = obj.find("bndbox")
  x1 = int(box.find('xmin').text)
  y1 = int(box.find('ymin').text)
  x2 = int(box.find('xmax').text)
  y2 = int(box.find('ymax').text)

  bndbox_coor = (x1, y1, x2, y2)
  class_name = obj.find('name').text

  cv2.rectangle(dst, (x1, y1), (x2, y2), color=class2color[class_name], thickness=1)
  cv2.putText(dst, class_name, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), thickness=1 )

  object_dict = {'class_name' : class_name, 'bndbox_coor' : bndbox_coor}
  object_list.append(object_dict)

print(object_list)
plt.figure(figsize=(10, 10))
plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))
```

```
[{'class_name': 'WBC', 'bndbox_coor': (109, 134, 324, 321)}, {'class_name': 'RBC', 'bndbox_coor': (432, 242, 528, 325)}, {'class_name': 'RBC', 'bndbox_coor': (510, 112, 606, 195)}, {'class_name': 'RBC', 'bndbox_coor': (482, 361, 594, 475)}, {'class_name': 'RBC', 'bndbox_coor': (75, 281, 166, 375)}, {'class_name': 'RBC', 'bndbox_coor': (38, 1, 147, 62)}, {'class_name': 'RBC', 'bndbox_coor': (288, 33, 390, 131)}, {'class_name': 'RBC', 'bndbox_coor': (411, 66, 527, 185)}, {'class_name': 'RBC', 'bndbox_coor': (1, 82, 102, 198)}, {'class_name': 'RBC', 'bndbox_coor': (1, 283, 81, 372)}, {'class_name': 'RBC', 'bndbox_coor': (1, 315, 78, 397)}, {'class_name': 'RBC', 'bndbox_coor': (391, 373, 469, 455)}, {'class_name': 'Platelets', 'bndbox_coor': (127, 47, 163, 81)}]
```

![image](https://user-images.githubusercontent.com/106129152/210732836-75f8d290-9dd5-40f3-b675-213215242af0.png)

### **BCCD Dataset을 COCO Format으로 변환**

github의 mmdet/datasets 디렉토리 아래 [coco.py](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py)에 CoCoDataset 클래스 정의

새로 정의한 데이터셋이 CoCoDataset을 상속받으므로 부모 클래스의 `init()`함수 적용

이 클래스 객체를 생성하는 것은 MMDetection Framework 내부에서 하며 이 때 Config에서 설정한 Dataset 관련 내용(이미지, 라벨 등이 위치한 디렉토리)들이 `init()`을 통해 설정되어 있음

**CocoDataset을 상속받는 경우에는 별다른 수정사항없이 현 데이터셋의 클래스만 변경**

```python
from mmdet.datasets.builder import DATASETS
from mmdet.datasets.coco import CocoDataset

@DATASETS.register_module(force=True) 
class BCCDDataset(CocoDataset):   
    CLASSES = ('WBC', 'RBC', 'Platelets')
```

### **Config 파일 수정**

아래 주어진 config 파일은 COCO dataset 기준으로 Faster R-CNN 을 훈련 시키는 설정이므로 BCCD Dataset 에 맞게 수정해야 함

```python
%pwd
# /content/mmdetection

from mmcv import Config
cfg = Config.fromfile('./configs/retinanet/retinanet_r101_fpn_1x_coco.py')
print(f'Config:\n{cfg.pretty_text}')
```

### **Pretrained 모델 다운로드**

```python
# We download the pre-trained checkpoints for inference and finetuning.
!mkdir checkpoints
!wget -c https://download.openmmlab.com/mmdetection/v2.0/retinanet/retinanet_r101_fpn_1x_coco/retinanet_r101_fpn_1x_coco_20200130-7a93545f.pth \
      -O checkpoints/retinanet_r101_fpn_1x_coco_20200130-7a93545f.pth
```

```python
from mmdet.apis import set_random_seed

# Modify dataset type and path
cfg.dataset_type = 'BCCDDataset'
cfg.data_root = 'BCCD_Dataset/BCCD/'

cfg.data.test.type = 'BCCDDataset'
cfg.data.test.data_root = 'BCCD_Dataset/BCCD/'
cfg.data.test.ann_file = 'test.json'
cfg.data.test.img_prefix = 'JPEGImages'

cfg.data.train.type = 'BCCDDataset'
cfg.data.train.data_root = 'BCCD_Dataset/BCCD/'
cfg.data.train.ann_file = 'train.json'
cfg.data.train.img_prefix = 'JPEGImages'

cfg.data.val.type = 'BCCDDataset'
cfg.data.val.data_root = 'BCCD_Dataset/BCCD/'
cfg.data.val.ann_file = 'val.json'
cfg.data.val.img_prefix = 'JPEGImages'

# modify num classes of the model in box head
cfg.model.bbox_head.num_classes = 3
# If we need to finetune a model based on a pre-trained detector, we need to
# use load_from to set the path of checkpoints.
cfg.load_from = 'checkpoints/retinanet_r101_fpn_1x_coco_20200130-7a93545f.pth'

# Set up working dir to save files and logs.
cfg.work_dir = '/content/drive/MyDrive/bccd_log'

# The original learning rate (LR) is set for 8-GPU training.
# We divide it by 8 since we only use one GPU.
cfg.optimizer.lr = 0.01/8
cfg.lr_config.warmup = None
cfg.log_config.interval = 10

# max epochs 12 
# cfg.runner.max_epochs = 12 # 기본값 변경시에만 설정

# 학습 시 Batch size 설정(단일 GPU 별 Batch size로 설정됨)
# samples_per_gpu 2 
# cfg.data.samples_per_gpu = 2 # 기본값 변경시에만설정

# CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)
# Change the evaluation metric since we use customized dataset.
# cfg.evaluation.metric = 'bbox' 
# We can set the evaluation interval to reduce the evaluation times
cfg.evaluation.interval = 12
# We can set the checkpoint saving interval to reduce the storage cost
cfg.checkpoint_config.interval = 12

# Set seed thus the results are more reproducible
cfg.seed = 0
set_random_seed(0, deterministic=False)
cfg.device = 'cuda'
cfg.gpu_ids = range(1)

# We can also use tensorboard to log the training process
cfg.log_config.hooks = [
    dict(type='TextLoggerHook'),
    dict(type='TensorboardLoggerHook')]

# We can initialize the logger for training and have a look
# at the final config used for training
print(f'Config:\n{cfg.pretty_text}')
```

### **Config에서 설정한 BCCD Dataset 적용**

`build_dataset()` 가 호출될 때 MMDetection Framework에서 BCCDDataset 클래스 객체를 생성

`load_annotations()` 함수가 호출될 때 `self.ann_file`, `self.data_root`, `self.img_prefix` 값이 Config에서 설정한 파일들로 적용되어 있음

```python
from mmdet.datasets import build_dataset

# Build dataset
train_datasets = [build_dataset(cfg.data.train)]
test_dataset =build_dataset(cfg.data.test)
```

```python
train_datasets # 205개의train imgage
```

![image](https://user-images.githubusercontent.com/106129152/210733036-731557cc-300e-45b6-9ceb-a599495be5ce.png)

```python
# train dataset 확인
train_datasets[0].__dict__.keys()

train_datasets[0].data_infos

train_datasets[0].pipeline
```

### **Config에서 설정한 모델 적용**

```python
from mmdet.models import build_detector

# Build the detector
model = build_detector(cfg.model)
# Add an attribute for visualization convenience
model.CLASSES = train_datasets[0].CLASSES
```

### **학습 수행**

```python
from google.colab import drive
drive.mount('/content/drive')

from mmdet.apis import train_detector

# Create work_dir
mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))
train_detector(model, train_datasets, cfg, distributed=False, validate=True) # validate=True : validation 데이터로 evaluation
```

```
2023-01-05 03:15:08,685 - mmdet - INFO -
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.871
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.670
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.170
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.463
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.715
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.715
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.715
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.193
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.628
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.796
```

### 로그 확인

```python
# load tensorboard in colab
%load_ext tensorboard

# see curves in tensorboard
%tensorboard --logdir /content/drive/MyDrive/bccd_log
```

![image](https://user-images.githubusercontent.com/106129152/210733078-dc10e044-e64a-43ce-8fac-5e5b3d5b75f4.png)

### 학습된 모델로 예측

**이미지 한 장 예측**

```python
from mmdet.apis import show_result_pyplot

img = mmcv.imread('BCCD_Dataset/BCCD/JPEGImages/BloodImage_00004.jpg')

model.cfg = cfg
result = inference_detector(model, img)
show_result_pyplot(model, img, result, score_thr=0.4)
```

![image](https://user-images.githubusercontent.com/106129152/210733112-2cbf0101-b8b1-44db-a6cf-30207de68498.png)

**이미지 여러 장 예측**

```python
import pandas as pd
test_df = pd.read_csv('./BCCD_Dataset/BCCD/ImageSets/Main/test.txt', header=None, names=['Image_name'])
test_img_paths = './BCCD_Dataset/BCCD/JPEGImages/' + test_df['Image_name'] + '.jpg'
test_imgs = [mmcv.imread(x) for x in test_img_paths.values]
len(test_imgs), test_imgs[0].shape
# (72, (480, 640, 3))
```

```python
for i in range(10):
  result = inference_detector(model_ckpt, test_imgs[i])
  show_result_pyplot(model_ckpt, test_imgs[i], result, score_thr=0.4)
```


### **TEST Evaluation**

```python
from mmdet.apis import multi_gpu_test, single_gpu_test
from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
from mmdet.apis import inference_detector, init_detector, show_result_pyplot

model_ckpt = MMDataParallel(model_ckpt, device_ids=[0])
# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함. 
# 위에서 만든 /content/show_test_output 디렉토리에 interence 결과가 시각화된 이미지가 저장됨. 
results = single_gpu_test(model_ckpt, data_loader, True, '/content/show_test_output', 0.3)

metric = test_dataset.evaluate(results, metric='bbox')
print(metric)
```

```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.899
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.678
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.717
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.717
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.757
```
