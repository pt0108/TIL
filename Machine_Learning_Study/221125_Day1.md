> 부트캠프 6주차 2022년 11월 25일

# 11/25 Machine Learning

## 머신러닝 개요

→ [머신러닝이란?](https://modulabs.co.kr/blog/machine-learning/)

**기계 학습**(機械學習) 또는 **머신 러닝**(machine learning)은 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구이다. 컴퓨터가 학습할 수 있도록 알고리즘과 기술을 개발하는 분야이다. ([위키피디아](https://ko.wikipedia.org/wiki/%EA%B8%B0%EA%B3%84_%ED%95%99%EC%8A%B5))

- **지도 학습**
    
    명확한 정답이 주어진 데이터를 학습 (분류, 회귀 등)
    
- **비지도 학습**
    
    정답이 없음, 주로 지도학습의 전처리 단계로 활용 (군집, 시각화, 차원 축소 등)
    
- **준지도 학습**
    
    정답이 없는 경우가 대다수, 정답이 있는 데이터는 소수
    
- **강화 학습, 배치 학습, 온라인 학습, 사례 기반 학습, 모델 기반 학습 등…**

훈련(또는 학습) : 주어진 데이터에서 비용 함수의 값이 가장 작아지는 모델 파라미터를 찾는 과정

**데이터 마이닝** : 대량 데이터 세트의 처리 및 탐색을 위한 분석에 사용되는 컴퓨터 지원 기법 → [aws/데이터 마이닝이란?](https://aws.amazon.com/ko/what-is/data-mining/)

***scikit-learn(사이킷런)**은 파이썬의 **머신러닝 라이브러리***

Classification 분류 - 이진 분류, 다중 분류

Regression 회귀 - 연속된 숫자를 예측

Clustering 클러스터링

Dimensionality reducation 차원 축소

Model selection 모델 선택

Preprocessing 전처리

··· 등을 지원한다.

→ [scikit-learn이란](https://engineer-mole.tistory.com/16), [scikit-learn 공식 문서](https://scikit-learn.org/stable/index.html)

→ [과대적합 및 과소적합 개념](https://heytech.tistory.com/125), [파라미터와 하이퍼 파라미터](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-13-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0Parameter%EC%99%80-%ED%95%98%EC%9D%B4%ED%8D%BC-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0Hyper-parameter)

## Day 1 - 붓꽃 품종 예측하기

***분류 예측 프로세스(요약)***

→ 데이터 세트 분리 > 모델 학습 > 예측 수행 > 평가

```python
import sklearn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
```

### 1. 데이터 적재

```python
from sklearn.datasets import load_iris
iris_data = load_iris()
```

### 2. 데이터 훑어보기

```python
type(iris_data)
# sklearn.utils.Bunch

iris_data.keys() # 데이터의 종류, key
# dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])

type(iris_data['data']), iris_data['data'].shape
# (numpy.ndarray, (150, 4))
```

```python
# 데이터
iris_data['data']

iris_data['feature_names'] # sepal : 꽃받침, petal : 꽃잎
# ['sepal length (cm)',
#  'sepal width (cm)',
#  'petal length (cm)',
#  'petal width (cm)']

print(iris_data['DESCR']) # 데이터의 요약 정보

iris_data['target'] # 타겟, 정답, 목표...
# array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
#        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])

iris_data['target_names'] # 0 : setosa, 1 : versicolor, 2 : virginica
# array(['setosa', 'versicolor', 'virginica'], dtype='<U10')
```

```python
# 가독성이 좋도록 dataframe으로 
iris_df = pd.DataFrame(iris_data['data'], columns=iris_data['feature_names'])

# dataframe에 target 컬럼 추가
iris_df['target'] = iris_data['target']

iris_df.head(3)
```

![image](https://user-images.githubusercontent.com/106129152/203925896-7e95e223-d100-4ea4-88ad-08b88d828ef0.png)

### 3. 데이터 탐색

```python
# 산점도로 확인
iris_df.plot(kind='scatter', x='sepal length (cm)', y='sepal width (cm)', c=iris_df['target'], cmap='plasma')
```

![image](https://user-images.githubusercontent.com/106129152/203925917-6cfa381d-b873-4948-bdf4-c6204293a61f.png)

```python
# 산점도 행렬
obj = pd.plotting.scatter_matrix(iris_df, marker='o', s=60, c=iris_df['target'], cmap='plasma', figsize=(24, 16))
```

![image](https://user-images.githubusercontent.com/106129152/203925941-f9e03582-db48-4350-b15c-2276491d9af3.png)

```python
# 데이터간의 상관계수
iris_df.corr()
```

![image](https://user-images.githubusercontent.com/106129152/203925972-85cefac9-6641-419f-bd22-148cf306b70a.png)

### 4. 데이터 준비 (데이터 세트 분리)

```python
from sklearn.model_selection import train_test_split
```

일반적으로 특성(행렬)은 X, 타겟(벡터)은 y로 표기한다.

```python
# 전체 데이터를 무작위로 섞은 후에 훈련데이터와 테스트 데이터를 나눠서 변환
# (특성 데이터, 타겟 데이터, 테스트 사이즈)
X_train, X_test, y_train, y_test = train_test_split(iris_data['data'], iris_data['target'], test_size=0.2, random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape
# ((120, 4), (30, 4), (120,), (30,))
```

### 5. 모델 학습

→ *[k*-NN 알고리즘](https://ko.wikipedia.org/wiki/K-%EC%B5%9C%EA%B7%BC%EC%A0%91_%EC%9D%B4%EC%9B%83_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98), [K-NN 알고리즘 (K-최근접 이웃) 개념](https://m.blog.naver.com/bestinall/221760380344)

```python
from sklearn.neighbors import KNeighborsClassifier
```

```python
# 인스턴스 = 모델객체() : 모델 생성
# 인스턴스.fit(훈련용 특성데이터, 정답) : 모델 훈련
# 인스턴스.predict(테스트용 특성데이터) : 모델 예측
```

```python
knn_clf = KNeighborsClassifier()

knn_clf.fit(X_train, y_train)
# KNeighborsClassifier()
```

### 6. 모델 예측

```python
# 예측한 것
y_pred = knn_clf.predict(X_test)
y_pred
# array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,
#       0, 2, 2, 2, 2, 2, 0, 0])

# 테스트의 정답
y_test
# array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,
#       0, 2, 2, 2, 2, 2, 0, 0])
```

### 7. 모델 평가

30개의 테스트 전부 정답인 것을 확인

```python
(y_pred == y_test).sum()
# 30
```
