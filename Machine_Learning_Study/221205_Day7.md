> 부트캠프 8주차 2022년 12월 5일

**참고하면 좋은 링크! → [sklearn 모듈을 이용한 전처리 파이프라인 만들기](https://rfriend.tistory.com/729)**

## 분류 평가 지표

→ [분류 성능평가](https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html), [분류평가지표](https://ysyblog.tistory.com/72), [분류](https://velog.io/@juyeonma9/%ED%95%B8%EC%A6%88%EC%98%A8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-2%ED%8C%90-3%EC%9E%A5-%EC%A0%95%EB%A6%AC), [MNIST 분류 비교](https://yerimoh.github.io/ML2/#---------)

회귀는 실제값과 예측값의 차이로 성능을 평가하지만,

분류는 성능 평가시 고려할 사항이 많다. 

### ****MNIST Dataset****

→ 미국 고등학생과 인구조사국 직원들이 쓴 손글씨 숫자 70,000개

```python
import numpy as np
from sklearn.datasets import fetch_openml
import matplotlib.pyplot as plt
```

### 데이터 가져오기

```python
mnist = fetch_openml("mnist_784", version=1, as_frame=False)
```

### 데이터 탐색하기

```python
type(mnist) # sklearn.utils.Bunch

mnist.keys()
# dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])

X = mnist['data']
y = mnist['target']

X.shape, y.shape # 70000개의 샘플에 대한 784개의 특성
# ((70000, 784), (70000,))

X[0].shape # 0번째 샘플의 데이터 크기
# (784,)
```

각 이미지가 28*28 픽셀로 구성되어 특성이 784개인 것! (→ 28*28=784)

```python
some_digit = X[0]
some_digit_img = some_digit.reshape(28, 28)
some_digit_img.shape # (28, 28)

plt.imshow(some_digit_img, cmap='binary')
```

![image](https://user-images.githubusercontent.com/106129152/205582564-04675412-3d59-42ac-8e2c-49a00bfd7d4e.png)

첫번째 특성(X[0])의 이미지를 알 수 있다.

그렇다면 위 이미지는 어떤 글자일까? 정답인 y로 확인해보자.

```python
y[0] # 현재 타입의 문자열
# '5'

y = y.astype(np.uint8)
y[0]
# 5
```

정답은 숫자 5인 것을 확인했다.

### 데이터 준비 (훈련 데이터, 테스트 데이터)

70000개의 데이터가 이미 뒤섞여진 상태이므로,

앞에서 6만개의 데이터를 훈련 데이터로 사용하고

뒤의 만개 데이터를 테스트 데이터로 사용한다.

```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```

각 label의 분포가 어떤지 살펴보자. 

```python
for i in range(10):
    print('label 분포 : ', i, (y_train == i).sum())
```

```
label 분포 :  0 5923
label 분포 :  1 6742
label 분포 :  2 5958
label 분포 :  3 6131
label 분포 :  4 5842
label 분포 :  5 5421
label 분포 :  6 5918
label 분포 :  7 6265
label 분포 :  8 5851
label 분포 :  9 5949
```

### 이진분류

정답이 5인지 아닌지로 분류하는 문제로 풀어보자.

```python
(y_train == 5).sum() # 10% (5인 데이터)
# 5421

60000 - (y_train == 5).sum() # 90% (5가 아닌 데이터)
# 54579

y_train_5 = (y_train == 5).astype(np.uint8) # 5인지 아닌지 분류: 5면 1, 아니면 0
y_test_5 = (y_test == 5).astype(np.uint8)

(y_train_5 == 1).sum(), (y_train_5 == 0).sum()
# (5421, 54579)
```

```python
from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(random_state=42)

# 교차검증
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf, X_train, y_train_5, scoring='accuracy', cv=3)
# array([0.95035, 0.96035, 0.9604 ])
```

하지만 위의 결과를 신뢰할 수 있을까? 

5인 데이터가 90%, 5가 아닌 데이터가 10%이기 때문에 전부 찍는다고 해도 무조건 90% 이상의 성능이 나올 것이다. **→ 위의 성능측정지표를 신뢰하기 어려움**

### 오차행렬(confusion matrix)

오차행렬은 분류 모델의 성능을 평가하기 위해 사용된다.

**어떤 유형의 오류가 발생했는지 나타내주는 지표**를 말한다.

오차행렬의 **행은 실제 클래스, 열은 예측 클래스**를 나타낸다.

**정밀도(Precition)**는 참이라고 예측한 것들 중, 참의 비율

**재현율(Recall)**은 실제로 참인 것 중, 참이라고 예측한 것의 비율

이 둘은 트레이드 오프, 즉 상호 반비례 관계이다.

정밀도가 늘어나면 재현율이 줄어들고, 재현율이 늘어나면 정밀도가 줄어든다.

→ [분류 성능 - 오차행렬](https://m.blog.naver.com/qbxlvnf11/221497600125), [정밀도와 재현율 구분](https://jennainsight.tistory.com/entry/%EC%A0%95%EB%B0%80%EB%8F%84precision%EC%99%80-%EC%9E%AC%ED%98%84%EC%9C%A8recall%EC%9D%98-%EC%98%A4%EC%B0%A8%ED%96%89%EB%A0%AC-%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80%EC%A7%80%ED%91%9C)

```python
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
from sklearn.model_selection import cross_val_predict
```

```python
# cross_val_predict(모델, X, y, cv=3)
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)

y_train_pred # y_train_pred.shape = (60000,)
# array([1, 0, 0, ..., 1, 0, 0], dtype=uint8)

confusion_matrix(y_train_5, y_train_pred)
# array([[53892,   687],
#        [ 1891,  3530]], dtype=int64)
```

```python
3530/(687+3530) # 정밀도
# 0.8370879772350012

3530/(1891+3530) # 재현율
# 0.6511713705958311
```

위와 같이 정밀도와 재현율을 구할 수 있고,

아예 sklearn의 함수에 정답과 예측을 넣어 사용하는 방법도 있다.

```python
precision_score(y_train_5, y_train_pred) # 정밀도
# 0.8370879772350012

recall_score(y_train_5, y_train_pred) # 재현율
# 0.6511713705958311

f1_score(y_train_5, y_train_pred) # F1 score
# 0.7325171197343846
```

F1 score는 정밀도와 재현율 둘 다 고려한 수치.

```python
y_train_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method='decision_function')

y_train_scores # 60000개 데이터에 대한 확신 점수 : 0보다 크면 양성, 작으면 음성
# array([  1200.93051237, -26883.79202424, -33072.03475406, ...,
#         13272.12718981,  -7258.47203373, -16877.50840447])

# 임계값 (확신 점수에 대한 임계값을 0에서 8000으로 올리면 '5'에 대한 예측이 정밀해짐)
threshold = 8000
y_train_pred_th8000 = y_train_scores > threshold

confusion_matrix(y_train_5, y_train_pred_th8000)
# array([[54470,   109],
#        [ 3863,  1558]], dtype=int64)

precision_score(y_train_5, y_train_pred_th8000)
# 0.9346130773845231

recall_score(y_train_5, y_train_pred_th8000)
# 0.2874008485519277
```

처음 기본값으로 오차행렬을 구한 것과 비교해보면 확연한 차이를 보이는 것을 알 수 있다. 정밀도가 상승하고, 재현율이 대폭 하락하였다. 

```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_train_scores)

plt.plot(thresholds, precisions[:-1], label='Precision')
plt.plot(thresholds, recalls[:-1], label='Recall')
plt.legend()
```

![image](https://user-images.githubusercontent.com/106129152/205582658-f5c981b6-53c5-47c4-9787-e7c8aaa168b9.png)

```python
# 정밀도가 90 이상이 나올 수 있는 값 구하기
thresholds[np.argmax(precisions >= 0.9)]
# 3370.0194991439557

thresholds = 3370
y_train_pred_th3370 = y_train_scores > thresholds
precision_score(y_train_5, y_train_pred_th3370)
# 0.9000345901072293
```

### ROC 곡선

FPR (False positive rate)과 TPR (True Positive Rate)을 각각 x, y축으로 놓은 그래프

**TPR (True Positive Rate, 특이도):** 1인 케이스에 대해 1로 바르게 예측하는 비율

**FPR (False positive rate, 거짓 양성 비율):** 0인 케이스에 대해 1로 틀리게 예측하는 비율

재현율(TPR)이 높을수록 거짓 양성(FPR)이 늘어난다.

좋은 분류기일수록 점선에서 멀리 떨어져있다.

**AUC(Area under the curve) :** 곡선 아래의 면적으로 완벽한 분류기는 AUC가 1이다. 아래 면적의 넓이가 크면 클수록 좋다.

→ [ROC curve와 AUC](https://bioinfoblog.tistory.com/221)

```python
from sklearn.metrics import roc_curve, plot_roc_curve, roc_auc_score

plot_roc_curve(sgd_clf, X_train, y_train_5)
```

![image](https://user-images.githubusercontent.com/106129152/205582722-9172a2ec-2002-4e42-813f-19b1e3884129.png)

`roc_auc_score(y_train_5, y_train_scores)` 를 사용해보면 `0.9604938554008616`가 나온다. 이진분류에서 ROC, AUC를 성능 측정지표로 많이 사용하지만, 위와 같이 불균형한 데이터셋에서는 재현율과 정밀도, F1 score를 보는게 더 바람직하다.

### 다중분류

**SVM Classifier (서포트 벡터 머신)**

```python
from sklearn.svm import SVC

svm_clf = SVC(random_state=42)
svm_scores = cross_val_score(svm_clf, X_train[:1000], y_train[:1000], cv=3)

svm_scores
# array([0.89520958, 0.9009009 , 0.88288288])
```

**SGD Classifier (경사하강법)**

```python
# 특성 스케일링 적용 전
sgd_clf = SGDClassifier(random_state=42) # 경사하강법
sgd_scores = cross_val_score(sgd_clf, X_train, y_train, cv=3)
sgd_scores 
# array([0.87365, 0.85835, 0.8689 ])

# 특성 스케일링 적용
from sklearn.preprocessing import StandardScaler
std_scaler = StandardScaler()
X_train_scaled = std_scaler.fit_transform(X_train)

sgd_scores = cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3)
sgd_scores # 교차 검증을 통한 각 폴드별 정확도(accuracy)
# array([0.8983, 0.891 , 0.9018])

y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
y_train_pred.shape # 각 폴드별 예측 결과 (60000개의 결과)
# (60000,)
```

`conf_mx = confusion_matrix(y_train, y_train_pred)`의 실행결과는 아래와 같다.

```
array([[5577,    0,   22,    5,    8,   43,   36,    6,  225,    1],
       [   0, 6400,   37,   24,    4,   44,    4,    7,  212,   10],
       [  27,   27, 5220,   92,   73,   27,   67,   36,  378,   11],
       [  22,   17,  117, 5227,    2,  203,   27,   40,  403,   73],
       [  12,   14,   41,    9, 5182,   12,   34,   27,  347,  164],
       [  27,   15,   30,  168,   53, 4444,   75,   14,  535,   60],
       [  30,   15,   42,    3,   44,   97, 5552,    3,  131,    1],
       [  21,   10,   51,   30,   49,   12,    3, 5684,  195,  210],
       [  17,   63,   48,   86,    3,  126,   25,   10, 5429,   44],
       [  25,   18,   30,   64,  118,   36,    1,  179,  371, 5107]],
      dtype=int64)

# conf_mx를 보면 유독 오답이 많은 구간이 숫자'8'에 대한 예측 구간이다
```

### 다중 레이블 분류

```python
from sklearn.neighbors import KNeighborsClassifier

y_train_large = (y_train >= 7) # True or False
y_train_odd = (y_train % 2 == 1) # Odd or Even
y_multilabel = np.c_[y_train_large, y_train_odd]

knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)

knn_clf.predict([some_digit]) 
# array([[False,  True]])
# '5' image에 대한 예측 : [False, True] -> 7보다 크지는 않지만 홀수

# 교차 검증으로 평가
cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)
f1_score(y_multilabel, y_train_knn_pred, average='macro')
# 0.976410265560605
```

### 다중 출력 분류

```python
# for train data
noise = np.random.randint(0, 100, (len(X_train), 784))
X_train_mod = X_train + noise

# for test data
noise = np.random.randint(0, 100, (len(X_test), 784))
X_test_mod = X_test + noise

# 깨끗한 원본 데이터를 정답 데이터로 만들기
y_train_mod = X_train
y_test_mod = X_test

# 훈련
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train_mod, y_train_mod)

# 예측
clean_digit = knn_clf.predict([X_test_mod[0]])
```

```python
# 시각화
# 노이즈가 들어간 특성 데이터
plt.imshow(X_test_mod[0].reshape(28, 28), cmap='binary')
```

![image](https://user-images.githubusercontent.com/106129152/205582773-a2b2098b-434c-4ed0-9c99-26322fe0d2aa.png)

```python
# 예측 결과
plt.imshow(clean_digit.reshape(28, 28), cmap='binary')
```

![image](https://user-images.githubusercontent.com/106129152/205582812-7d0f162d-11fb-4df3-b8b2-4213872ead96.png)

```python
# 정답
plt.imshow(y_test_mod[0].reshape(28, 28), cmap='binary')
```

![image](https://user-images.githubusercontent.com/106129152/205582838-cf911dbe-7518-4b2d-ab1c-bb136b59b6fc.png)
