## Mini Project 2 - 머신러닝 성능 올리기

**분석할 데이터셋**

[Spaceship Titanic](https://www.kaggle.com/competitions/spaceship-titanic/data?select=test.csv)

> *Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!*
> 

Overview에 있는 설명을 읽어보면, 우주선 타이타닉이 시공간 이상(?)과 충돌하였고, 배는 손상되지 않았지만 거의 절반의 승객들이 다른 차원으로 옮겨졌다고 한다. 여기서 Transported가 바로 예측해야할 값이다. 그런고로, 이 문제는 이진 분류 문제라고 볼 수 있다. True / False로 판별이 가능하니까!

```
**PassengerId** - 각 승객의 고유 ID
**HomePlanet** - 승객이 출발한 행성 (승객의 고향)
**CryoSleep** - 승객의 냉동수면 여부? CyroSleep 중인 승객은 객실에 갇혀 있음
**Cabin** - 객실 번호 (deck/num/side), side = Port=P(좌현), Starboard=S(우현)
**Destination** - 승객의 목적지
**Age** - 승객의 나이
**VIP** - VIP 여부
**RoomService, FoodCourt, ShoppingMall, Spa, VRDeck** - 승객이 각종 편의시설에 대해 지불한 금액
**Name** - 승객의 이름
**Transported** - 승객이 다른 차원으로 이동했는지 여부. 이 문제의 타겟, 예측해야할 목표.
```

자세한 분석 과정은 링크의 노트북을 확인하면 된다.

**1차 분석** 

[Spaceship_Titanic/Spaceship Titanic.ipynb at main · pt0108/Spaceship_Titanic](https://github.com/pt0108/Spaceship_Titanic/blob/main/Spaceship%20Titanic.ipynb)

**2차 분석**

[Spaceship_Titanic/Spaceship Titanic 2.ipynb at main · pt0108/Spaceship_Titanic](https://github.com/pt0108/Spaceship_Titanic/blob/main/Spaceship%20Titanic%202.ipynb)

→ 1차 분석과 2차 분석의 차이점은 적재된 데이터의 내용과 전처리에 있다.

1차로 분석을 할 때는 각 특성들과 타겟의 연관성을 잘 찾아내지 못했던 것 같다. 아직 머신 러닝의 모델 학습을 하는 일련의 과정이 익숙치 않아서 전처리도 미흡했다. 정규화나, 표준화, 로그 스케일링 등… 수치형 데이터에 대해 특성 스케일링이 부족했다.

다음날, 다시 2차 분석을 할 때는 Cabin 특성의 Num을 버리지 않고, 타겟과의 유의미한 연관성을 발견하고 그대로 사용했다. 그리고 처음 데이터를 훑어볼 때 수치형 데이터들이 꼬리가 긴 분포를 보이는 것을 확인할 수 있는데, 이에 로그 스케일링을 적용했다. 

결과적으로는 1차 분석 때 0.745~ 가량의 결과가 나왔다면, 2차 분석 때는 0.802~ 정도로 성능이 향상된 것을 확인할 수 있었다.

그리고 2차 분석 때 알게된 사실이 하나 있는데, seaborn에서 histplot을 그릴 때 값이 int type이면 제대로 표현되지 않던 그래프가 float type으로 변환 후 잘 표현되는 것을 발견했다.

또, 학습을 마친 최적의 모델(여기서는 GradientBoostingClassifier)을 저장해서 submission으로 제출하고 싶었는데 모델의 테스트 데이터와 submission 데이터의 크기가 맞지 않아서 계속 오류가 났었다. 알고 보니 모델이 예측할 데이터에 test 데이터를 넣었어야 했던 것을, train 데이터 중 X_test로 스플릿된 데이터를 집어 넣는 실수를 해서 그랬던 것이었다. 이를 알고 수정하니 제출에 성공하였다.

직접 데이터를 분석하고, 모델을 학습시키고, 처음으로 캐글의 competition에 submission 제출을 해본 소중한 경험이었다. 새삼스럽게도, 데이터의 전처리가 정말정말 중요한 부분이라는 걸 다시금 깨닫는 기회가 되었다.
