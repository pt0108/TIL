> 부트캠프 7주차 2022년 11월 29일

## 보스톤 주택 가격 예측

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_boston
```

### 1. 데이터 탐색

```
CRIM     per capita crime rate by town
 ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
 INDUS    proportion of non-retail business acres per town
 CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
 NOX      nitric oxides concentration (parts per 10 million)
 RM       average number of rooms per dwelling
 AGE      proportion of owner-occupied units built prior to 1940
 DIS      weighted distances to five Boston employment centres
 RAD      index of accessibility to radial highways
 TAX      full-value property-tax rate per $10,000
 PTRATIO  pupil-teacher ratio by town
 B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
 LSTAT    % lower status of the population
 MEDV     Median value of owner-occupied homes in $1000's
```

- CRIM: 지역별 범죄 발생률
- ZN: 25,000평방피트를 초과하는 거주 지역의 비율
- NDUS: 비상업 지역 넓이 비율
- CHAS: 찰스강에 대한 더미 변수(강의 경계에 위치한 경우는 1, 아니면 0)
- NOX: 일산화질소 농도
- RM: 거주할 수 있는 방 개수
- AGE: 1940년 이전에 건축된 소유 주택의 비율
- DIS: 5개 주요 고용센터까지의 가중 거리
- RAD: 고속도로 접근 용이도
- TAX: 10,000달러당 재산세율
- PTRATIO: 지역의 교사와 학생 수 비율
- B: 지역의 흑인 거주 비율
- LSTAT: 하위 계층의 비율
- MEDV: 본인 소유의 주택 가격(중앙값)

DataFrame으로 준비

```python
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['PRICE'] = boston['target']
df.head()
```

![image](https://user-images.githubusercontent.com/106129152/204468735-0bd11a1c-7b8c-4af1-a337-c884d575f945.png)

누락 데이터 확인

```python
df.info()
```

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 506 entries, 0 to 505
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype
---  ------   --------------  -----
 0   CRIM     506 non-null    float64
 1   ZN       506 non-null    float64
 2   INDUS    506 non-null    float64
 3   CHAS     506 non-null    float64
 4   NOX      506 non-null    float64
 5   RM       506 non-null    float64
 6   AGE      506 non-null    float64
 7   DIS      506 non-null    float64
 8   RAD      506 non-null    float64
 9   TAX      506 non-null    float64
 10  PTRATIO  506 non-null    float64
 11  B        506 non-null    float64
 12  LSTAT    506 non-null    float64
 13  PRICE    506 non-null    float64
dtypes: float64(14)
memory usage: 55.5 KB
```

통계 정보

```python
df.describe()
```

![image](https://user-images.githubusercontent.com/106129152/204468769-1d0959eb-de66-4e29-8ba5-49126fd79cb4.png)

시각화

```python
h = df.hist(bins=50, figsize=(20, 15))
```

![image](https://user-images.githubusercontent.com/106129152/204468793-a2632e63-3062-4568-8b0e-dcef8d820c24.png)

상관계수

```python
plt.figure(figsize=(12, 8))
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, fmt='.2f')
```

![image](https://user-images.githubusercontent.com/106129152/204468826-a92be69c-7592-49cf-a286-676c5ebd4626.png)

```python
# 하위 계층의 비율과 주택 가격
df.plot(kind='scatter', x='LSTAT', y='PRICE', alpha=0.8)
```

![image](https://user-images.githubusercontent.com/106129152/204468861-f528f9a2-9e40-4ed0-beb7-f4c78738f786.png)

```python
# 거주할 수 있는 방의 개수와 주택 가격
df.plot(kind='scatter', x='RM', y='PRICE', alpha=0.8)
```

![image](https://user-images.githubusercontent.com/106129152/204468895-431db6ea-9398-4bbc-9ed3-a2f7f3e492de.png)

### 2. 데이터 준비

```python
from sklearn.model_selection import train_test_split
X = df.drop('PRICE', axis=1)
y = df['PRICE']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
# (404, 13) (102, 13) (404,) (102,)
```

### 3. 모델 훈련

**3.1 기본 선형 모델**

기본 선형모델(정규방정식)

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error # MSE

# 교차검증을 사용하지 않은 경우(잘못된 방법)
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
y_pred = lin_reg.predict(X_test)
# squared=False : MSE의 제곱근값 -> RMSE
rmse = mean_squared_error(y_test, y_pred, squared=False) 
rmse # 4.928602182665355
```

```python
from sklearn.model_selection import cross_val_score

# 교차검증을 사용한 경우 : cross_val_score
lin_reg = LinearRegression()

scores = cross_val_score(lin_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5)
lin_reg_rmse = np.sqrt((-scores).mean())
lin_reg_rmse # 4.86358080742005
```

→ [교차검증(cross-validation)](https://homeproject.tistory.com/6)

기본 선형모델(경사하강법 + 특성스케일링)

```python
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler # 평균을 0, 분산을 1로 변환

# 교차검증 사용

std_scaler = StandardScaler()
X_train_scaled = std_scaler.fit_transform(X_train)

sgd_reg = SGDRegressor(penalty=None, random_state=42)
scores = cross_val_score(sgd_reg, X_train_scaled, y_train, scoring='neg_mean_squared_error', cv=5)
sgd_reg_rmse = np.sqrt((-scores).mean())
sgd_reg_rmse # 4.898581570477037

X_train_scaled.mean(), X_train_scaled.std() 
# (-9.740875280793452e-17, 1.0)
# mean값이 0, std값이 1에 근접하는 것을 알 수 있음
```

**3.2 다항 회귀 모델**

```python
X_train.columns
# Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',
#       'PTRATIO', 'B', 'LSTAT'],
#      dtype='object')
```

```python
from sklearn.preprocessing import PolynomialFeatures # 변환기

poly_feature = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly_feature.fit_transform(X_train)
X_train.shape, X_train_poly.shape
# ((404, 13), (404, 104))
```

```python
# 다항 회귀 (정규방정식)
lin_reg = LinearRegression()

# 교차검증
scores = cross_val_score(lin_reg, X_train_poly, y_train, scoring='neg_mean_squared_error', cv=5)
poly_lin_reg_rmse = np.sqrt(-scores.mean())
poly_lin_reg_rmse
# 4.349154691332248
```

```python
# 다항 회귀 (경사하강법)
# (1) Poly(제곱특성 추가) -> (2) STD Scale(표준화) -> (3) SGDRegressor (경사하강법)

# (1) Poly(제곱특성 추가)
poly_feature = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly_feature.fit_transform(X_train)

# (2) STD Scale(표준화)
std_scaler = StandardScaler()
X_train_poly_scaled = std_scaler.fit_transform(X_train_poly)

# (3) SGDRegressor (경사하강법)
sgd_reg = SGDRegressor(penalty=None, random_state=42)
scores = cross_val_score(sgd_reg, X_train_poly_scaled, y_train, scoring='neg_mean_squared_error', cv=5)
sgd_reg_rmse = np.sqrt((-scores).mean())
sgd_reg_rmse 
# 3.8507394341607575
```

아래와 같이 사이킷런에서 제공하는 파이프라인을 사용해도 같은 결과가 나온다.

```python
from sklearn.pipeline import Pipeline

# 다항 회귀 (경사하강법) with.Pipelin
# (1) Poly(제곱특성 추가) -> (2) STD Scale(표준화) -> (3) SGDRegressor (경사하강법)

# (1) Poly(제곱특성 추가) -> (2) STD Scale(표준화)
poly_std_pipeline = Pipeline([
                            ('poly', PolynomialFeatures(degree=2, include_bias=False)),
                            ('std_scaler', StandardScaler())
                            ])
X_train_poly_scaled = poly_std_pipeline.fit_transform(X_train)

# (3) SGDRegressor (경사하강법)
sgd_reg = SGDRegressor(penalty=None, random_state=42)
scores = cross_val_score(sgd_reg, X_train_poly_scaled, y_train, scoring='neg_mean_squared_error', cv=5)
sgd_reg_rmse = np.sqrt((-scores).mean())
sgd_reg_rmse
# 3.8507394341607575
```

**3.3 규제 모델**

모델 파라미터 규제가 되는지 확인(교차검증 사용하지 않음)

```python
from sklearn.linear_model import Ridge, Lasso, ElasticNet
```

기본 선형 회귀 모델

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

lin_coef = pd.Series(lin_reg.coef_, index=X_train.columns)
lin_coef_sort = lin_coef.sort_values(ascending=False)
sns.barplot(x=lin_coef_sort.values, y=lin_coef_sort.index)
```

![image](https://user-images.githubusercontent.com/106129152/204468985-93cbcb73-813a-4f76-afb9-5b87cc9bfa26.png)

릿지 회귀(Ridge)

```python
alphas = [0, 0.1, 1, 10, 100]

coef_df = pd.DataFrame()
for alpha in alphas:
    ridge_reg = Ridge(alpha=alpha, random_state=42)
    ridge_reg.fit(X_train, y_train)

    ridge_coef = pd.Series(ridge_reg.coef_, index=X_train.columns)
    ridge_coef_sort = ridge_coef.sort_values(ascending=False)
    
    column = 'alpha : ' + str(alpha)
    coef_df[column] = ridge_coef_sort
    
coef_df
```

![image](https://user-images.githubusercontent.com/106129152/204469028-3f875ad2-b5f2-41f0-8627-5092f088dd7f.png)

라쏘 회귀

```python
alphas = [0.05, 0.1, 0.2, 0.5, 1]

coef_df = pd.DataFrame()
for alpha in alphas:
    lasso_reg = Lasso(alpha=alpha, random_state=42)
    lasso_reg.fit(X_train, y_train)

    lasso_coef = pd.Series(lasso_reg.coef_, index=X_train.columns)
    lasso_coef_sort = lasso_coef.sort_values(ascending=False)
    
    column = 'alpha : ' + str(alpha)
    coef_df[column] = lasso_coef_sort
    
coef_df
```

![image](https://user-images.githubusercontent.com/106129152/204469059-b09f0a8b-77d2-473f-89d8-ec48af9eb352.png)

엘라스틱넷(ElasticNet)

```python
alphas = [0.05, 0.1, 0.2, 0.5, 1]

coef_df = pd.DataFrame()
for alpha in alphas:
    elastic_reg = ElasticNet(alpha=alpha, random_state=42)
    elastic_reg.fit(X_train, y_train)

    elastic_coef = pd.Series(elastic_reg.coef_, index=X_train.columns)
    elastic_coef_sort = elastic_coef.sort_values(ascending=False)
    
    column = 'alpha : ' + str(alpha)
    coef_df[column] = elastic_coef_sort
    
coef_df
```

![image](https://user-images.githubusercontent.com/106129152/204469093-3999f864-86c2-40f3-a863-52163d2f6865.png)
