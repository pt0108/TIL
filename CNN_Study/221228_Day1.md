> 부트캠프 11주차 2022년 12월 28일

# FMNIST - (4) 조기 종료, LR Schedule

→ [콜백 함수](https://deep-deep-deep.tistory.com/56)([파이토치](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html)도 동일 함수 제공)

이번에는 지난 시간에 했던 FMNIST에 조기 종료와, LR Schedule 코드를 추가해보았다.

LR Scheduler는 ****모델의 개선이 없을 경우, Learning Rate를 조절해 모델의 개선을 유도하는 콜백함수이다. 아래 코드는 *5. 모델 컴파일* 단계에서 추가했다.

```python
# monitoring 하고 있는 값(valid_loss)이 patience 기간동안(onPlateau) 줄어들지 않을 때 lr에 factor(0.1)를 곱해줌
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)
```

*6. 모델 훈련* 단계에서 조기 종료 코드와 LR Schedule 코드를 추가 적용.

```python
def train(model, epochs, criterion, optimizer):
  steps = 0
  min_loss = 10000
  max_accuracy = 0
  trigger = 0
  patience = 10 # for Early Stopping

  # 1 에폭(epoch)당 반복수
  #steps_per_epoch = len(trainset)/batch_size # 3125 iterations
  steps_per_epoch = len(trainloader) # 3125 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
      steps += 1
      # 1. 입력 데이터 준비
      images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      outputs = model.forward(images) # 예측
      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

      # 3. 역방향(Backward) 오차(Gradient) 전파
      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
      loss.backward()

      # 4. 경사하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0: # step : 3125, .... (epoch 마다)
        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad 시각화를 위한 로그 이벤트 등록
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
        
        # Best model 저장
        # option 1
        # if valid_loss < min_loss:
        #   min_loss = valid_loss
        #   torch.save(model.state_dict(), 'best_checkpoint.pth')

        # option 2
        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping (조기 종료)
        if valid_loss > min_loss:
          trigger += 1 # valid loss가 min loss를 갱신하지 못할 때마다 증가
          print('trigger : ', trigger)
          if trigger > patience:
            print('Early Stopping!!')
            print('Training step is finished!!')
            writer.flush()   
            return
        else:
          trigger = 0
          min_loss = valid_loss

        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)

  writer.flush()
```

```python
epochs = 50
train(model, epochs, criterion, optimizer)
```

모델을 학습시키면, trigger가 일정 조건에 도달했을 때 LR Scheduler로 인해 다시 learning rate가 조정되는 것을 확인할 수 있다.

![image](https://user-images.githubusercontent.com/106129152/209785107-6650e41c-fd0f-4c7a-814c-ae89e7b52739.png)

이 모델의 best model 성능은 0.8784, last model 성능은 0.8765로 나왔다.

자세한 것은 노트북 확인!

# 합성곱 신경망(CNN)

→ [CNN 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375)

일반 DNN은 1차원 데이터를 사용한다. 이 과정에서 정보 손실과 효율성 저하를 일으킨다.

그러나 **합성곱 계층은 형상을 유지**한다. 이미지도 3차원 데이터로 입력받고, 다음 계층에도 3차원 데이터로 전달한다. 그러므로 CNN은 형상을 가진 데이터를 제대로 이해할 것!

합성곱 계층의 입출력 데이터를 *feature map* 이라고 하는데, 이것의 입력 데이터를 *input feature map*, 출력 데이터를 *output feature map*이라고 한다.

합성곱 계층에서는 **합성곱 연산**을 처리하는데, 이는 **필터 연산**을 말한다. OpenCV에서 배웠던 것을 생각하면 이해하기 쉬움! 

**스트라이드(stride)** : 필터를 적용하는 위치의 간격, 클수록 출력 크기가 줄어든다.

**풀링 계층 : 2차원 데이터의 세로 및 가로 방향의 공간을 줄이는 연산**

- 학습해야 할 매개변수가 없음
- 채널 수가 변하지 않고, 입력 변화에 영향을 적게 받음

합성곱 계층은 여러 겹 쌓을수록 층이 깊어지면서 더 목잡하고 추상화된 정보가 추출된다. 

# FMNIST

```python
import torch # 파이토치 기본 라이브러리 
import torchvision # 이미지 관련 된 파이토치 라이브러리
from torchvision import datasets # 토치비전에서 제공하는 데이터셋
from torchvision import transforms # 이미지 전처리 기능들을 제공하는 라이브러리
from torch.utils.data import DataLoader # 데이터를 모델에 사용할 수 있도록 적재해 주는 라이브러리
from torch.utils.data import random_split
import numpy as np 
import matplotlib.pyplot as plt
```

## (1)CNN 기본 모델

![image](https://user-images.githubusercontent.com/106129152/209785156-49b985b9-25b9-4e75-810f-956a9045c995.png)

이번에는 구글 코랩의 GPU를 사용! 

데이터를 적재하는 과정까지는 이전에 파이토치로 FMNIST를 했던 것과 동일하다.

```python
!nvidia-smi

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device # device(type='cuda')
```

### 4. 모델 생성

```python
from torch import nn # 파이토치에서 제공하는 다양한 계층(Linear layer, Convolutional Layer...)
from torch import optim # 옵티마이저 (경사하강법...)
import torch.nn.functional as F # 파이토치에서 제공하는 함수(활성화 함수...)
```

![image](https://user-images.githubusercontent.com/106129152/209785176-bb713c13-72b9-4d84-8809-ef8752842404.png)

```python
class FMNIST_CNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Sequential(
        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 32 * 14 * 14
    self.conv2 = nn.Sequential(
        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 64 * 7 * 7

    self.fc1 = nn.Linear(in_features=64*7*7, out_features=128)
    self.fc2 = nn.Linear(in_features=128, out_features=10)

  def forward(self, x):
    x = self.conv1(x) # 32 * 14 * 14
    x = self.conv2(x) # 64 * 7 * 7
    x = x.view(-1, 64*7*7) # Flatten
    x = self.fc1(x)
    x = self.fc2(x)

    return x
```

```python
# nn.Module을 상속받아 Class를 만드는 방법 이외에도
# 간단한 망을 구성할 때는 아래와 같이 nn.Sequential을 사용해도 됨
# model = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
#                       nn.ReLU(),
#                       nn.MaxPool2d(kernel_size=2, stride=2), # 32 * 14 * 14
                      
#                       nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
#                       nn.ReLU(),
#                       nn.MaxPool2d(kernel_size=2, stride=2), # 64 * 7 * 7

#                       nn.Flatten(), # 3136 (= 64 * 7 * 7)
#                       nn.Linear(in_features=3136, out_features=128),
#                       nn.Linear(in_features=128, out_features=10)
#                       )
```

```python
model = FMNIST_CNN()
model.to(device)
model
```

![image](https://user-images.githubusercontent.com/106129152/209785196-845225ee-59dd-4d76-a1db-1b5025cf2c8f.png)

```python
for name, parameter in model.named_parameters():
  print(name, parameter.size())
# conv1.0.weight torch.Size([32, 1, 3, 3])
# conv1.0.bias torch.Size([32])
# conv2.0.weight torch.Size([64, 32, 3, 3])
# conv2.0.bias torch.Size([64])
# fc1.weight torch.Size([128, 3136])
# fc1.bias torch.Size([128])
# fc2.weight torch.Size([10, 128])
# fc2.bias torch.Size([10])
```

```python
from torchsummary import summary
summary(model, (1, 28, 28)) # (channle, input_size) 
```

![image](https://user-images.githubusercontent.com/106129152/209785226-0ac8f143-e4b2-479f-bdcb-717fcf77b9a0.png)

### 5. 모델 컴파일

```python
learning_rate = 0.001 
# 손실함수
criterion = nn.CrossEntropyLoss()
# 옵티마이저(경사하강법, 최적화 함수)
#optimizer = optim.SGD(model.parameters(), lr = learning_rate)
# 규제의 강도 설정 weight_decay
# optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=0.001)
optimizer = optim.Adam(model.parameters(), lr = learning_rate)

# LR Scheduler : 모델의 개선이 없을 경우, Learning Rate를 조절해 모델의 개선을 유도하는 콜백함수
# monitoring 하고 있는 값(valid_loss)이 patience 기간동안(onPlateau) 줄어들지 않을 때 lr에 factor(0.1)를 곱해줌
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)
```

### 6. 모델 훈련

```python
def validation(model, validloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  valid_accuracy = 0
  valid_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28
      
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 100개에 대한 loss
      
      valid_accuracy += accuracy
      valid_loss += loss.item() # tensor 값을 꺼내옴
    

  return valid_loss, valid_accuracy # 100세트 전체 대한 총 loss, 총 accuracy
```

```python
from torch.utils.tensorboard import SummaryWriter
writer  = SummaryWriter()

def train(model, epochs, criterion, optimizer):
  steps = 0
  min_loss = 10000
  max_accuracy = 0

  trigger = 0
  patience = 10 # for Early stopping

  # 1 에폭(epoch)당 반복수
  #steps_per_epoch = len(trainset)/batch_size # 3125 iterations
  steps_per_epoch = len(trainloader) # 3125 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
      steps += 1
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력 데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      outputs = model.forward(images) # 예측
      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

      # 3. 역방향(Backward) 오차(Gradient) 전파
      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
      loss.backward()

      # 4. 경사하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0: # step : 3125, .... (epoch 마다)
        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad 시각화를 위한 로그 이벤트 등록
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
        
        # Best model 저장
        # option 1
        # if valid_loss < min_loss:
        #   min_loss = valid_loss
        #   torch.save(model.state_dict(), 'best_checkpoint.pth')

        # option 2
        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping (조기 종료)
        if valid_loss > min_loss:
          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가
          print('trigger : ', trigger )
          if trigger > patience:
            print('Early Stopping!!!')
            print('Traning step is finished!!')
            writer.flush()  
            return   
        else:
          trigger = 0
          min_loss = valid_loss

        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)

  writer.flush()

epochs = 50
train(model, epochs, criterion, optimizer)
```

![image](https://user-images.githubusercontent.com/106129152/209785259-79398746-eaea-4125-a402-b32d5ce9c4de.png)

![image](https://user-images.githubusercontent.com/106129152/209785279-59ef883d-2000-499f-9d36-c154869e6f1e.png)

![image](https://user-images.githubusercontent.com/106129152/209785292-d8e2d084-0589-43b5-8060-929d909a2cb5.png)

과적합이 일어난 것을 볼 수 있다. 

이를 줄이기 위해, 추가로 노트북을 생성해 성능 개선을 할 것이다.

### 7. 모델 예측

```python
test_iter = iter(testloader)
images, labels = next(test_iter)
images, labels = images.to(device), labels.to(device)
print(images.size(), labels.size())
# torch.Size([16, 1, 28, 28]) torch.Size([16])

rnd_idx = 10
images[rnd_idx].shape, labels[rnd_idx] # 1, 28, 28
# (torch.Size([1, 28, 28]), tensor(4, device='cuda:0'))

# not Flatten!
# flattend_img = images[rnd_idx].view(1, 784)
with torch.no_grad():
  model.eval() # 배치 정규화가 들어가면서 전방향 연산이 학습시와는 달라지므로 반드시 eval() 넣어야 함
  logit = model.forward(images[rnd_idx])

pred = logit.max(dim=1)[1]
pred == labels[rnd_idx]
# tensor([True], device='cuda:0')
```

```python
img = images[rnd_idx][0]
img = img.cpu()
plt.imshow(img, cmap='gray')
```

![image](https://user-images.githubusercontent.com/106129152/209785320-76393612-14f8-44eb-aabf-6c2607d09497.png)

### 8. 모델 평가

```python
def evaluation(model, testloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  test_accuracy = 0
  test_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    model.eval()
    for images, labels in testloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) (10000/16)번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()
      
      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      test_accuracy += accuracy.item()
      test_loss += loss.item() # tensor 값을 꺼내옴
    

  print('Test Loss : ', test_loss/len(testloader))
  print('Test Accuracy : ', test_accuracy/len(testloader))

evaluation(model, testloader, criterion)
# Test Loss :  0.35493649395549437
# Test Accuracy :  0.9154
```

### 9. 모델 저장

```python
torch.save(model.state_dict(), 'last_checkpoint.pth')

last_state_dict = torch.load('last_checkpoint.pth')

last_model = FMNIST_CNN()
last_model.to(device)
last_model.load_state_dict(last_state_dict)
# <All keys matched successfully>

evaluation(last_model, testloader, criterion)
# Test Loss :  0.35493649395549437
# Test Accuracy :  0.9154

best_state_dict = torch.load('best_checkpoint.pth')

best_model = FMNIST_CNN()
best_model.to(device)
best_model.load_state_dict(best_state_dict)
# <All keys matched successfully>

evaluation(best_model, testloader, criterion)
# Test Loss :  0.32872194311860947
# Test Accuracy :  0.9176
```

## (2) CNN 성능 개선

이제 추가로 기본 모델의 성능을 개선해보자.

모델의 생성 과정에서 성능을 개선시킬 수 있는 요소들을 추가.

```python
class FMNIST_CNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Sequential(
        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
        nn.BatchNorm2d(num_features=32),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 32 * 14 * 14
    self.conv2 = nn.Sequential(
        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
        nn.BatchNorm2d(num_features=64),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 64 * 7 * 7

    self.conv3 = nn.Sequential(
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
        nn.BatchNorm2d(num_features=128),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 128 * 3 * 3

    self.fc1 = nn.Linear(in_features=128*3*3, out_features=128)
    self.bn1 = nn.BatchNorm1d(num_features=128)
    self.fc2 = nn.Linear(in_features=128, out_features=10)

  def forward(self, x):
    x = self.conv1(x) # 32 * 14 * 14
    x = self.conv2(x) # 64 * 7 * 7
    x = self.conv3(x) # 128 * 3 * 3
    x = x.view(-1, 128*3*3) # Flatten
    x = self.fc1(x)
    x = self.bn1(x)
    x = F.dropout(x, 0.5)
    x = self.fc2(x)

    return x
```

이렇게 해서 만들어진 모델은 아래와 같다.

![image](https://user-images.githubusercontent.com/106129152/209785376-5da0f351-18a4-41d4-8f06-1610c6bc3c48.png)

![image](https://user-images.githubusercontent.com/106129152/209785406-c22a9d47-94ca-43bb-b951-daeadbf725cd.png)

다음은 모델의 훈련 과정이다. (역시 자세한 것은 코랩 파일 확인)

```python
def validation(model, validloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  valid_accuracy = 0
  valid_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28
      
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 100개에 대한 loss
      
      valid_accuracy += accuracy
      valid_loss += loss.item() # tensor 값을 꺼내옴
    

  return valid_loss, valid_accuracy # 100세트 전체 대한 총 loss, 총 accuracy
```

```python
from torch.utils.tensorboard import SummaryWriter
writer  = SummaryWriter()

def train(model, epochs, criterion, optimizer):
  steps = 0
  min_loss = 10000
  max_accuracy = 0

  trigger = 0
  patience = 10 # for Early stopping

  # 1 에폭(epoch)당 반복수
  #steps_per_epoch = len(trainset)/batch_size # 3125 iterations
  steps_per_epoch = len(trainloader) # 3125 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
      steps += 1
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력 데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      outputs = model.forward(images) # 예측
      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

      # 3. 역방향(Backward) 오차(Gradient) 전파
      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
      loss.backward()

      # 4. 경사하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0: # step : 3125, .... (epoch 마다)
        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad 시각화를 위한 로그 이벤트 등록
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
        
        # Best model 저장
        # option 1
        # if valid_loss < min_loss:
        #   min_loss = valid_loss
        #   torch.save(model.state_dict(), 'best_checkpoint.pth')

        # option 2
        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping (조기 종료)
        if valid_loss > min_loss:
          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가
          print('trigger : ', trigger )
          if trigger > patience:
            print('Early Stopping!!!')
            print('Traning step is finished!!')
            writer.flush()  
            return   
        else:
          trigger = 0
          min_loss = valid_loss

        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)

  writer.flush()

epochs = 50
train(model, epochs, criterion, optimizer)
```

이런 식으로 트레이닝이 진행되었다.

![image](https://user-images.githubusercontent.com/106129152/209785683-a581bda9-e6cf-4b61-adb1-c637d39f13b4.png)

![image](https://user-images.githubusercontent.com/106129152/209785702-2dc222a3-cfc9-4c42-bf8b-1d2422167432.png)

![image](https://user-images.githubusercontent.com/106129152/209785734-e173dc37-ccea-4b67-81e4-3f041da81bac.png)

다음은 모델의 평가 과정 코드이다.

```python
def evaluation(model, testloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  test_accuracy = 0
  test_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    model.eval()
    for images, labels in testloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) (10000/16)번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()
      
      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      test_accuracy += accuracy.item()
      test_loss += loss.item() # tensor 값을 꺼내옴
    

  print('Test Loss : ', test_loss/len(testloader))
  print('Test Accuracy : ', test_accuracy/len(testloader))
```

![image](https://user-images.githubusercontent.com/106129152/209785754-1be80d0e-9e99-41ff-b644-653c60e980d6.png)

last 모델의 성능은 0.9289, best 모델의 성능은 0.9298 이 나왔다.

확실히 기본 모델보다 더 향상된 성능임을 알 수 있다!
