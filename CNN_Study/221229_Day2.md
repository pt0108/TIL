> 부트캠프 11주차 2022년 12월 29일

# CIFAR10 (1)

```python
import torch # 파이토치 기본 라이브러리 
import torchvision # 이미지 관련 된 파이토치 라이브러리
from torchvision import datasets # 토치비전에서 제공하는 데이터셋
from torchvision import transforms # 이미지 전처리 기능들을 제공하는 라이브러리
from torch.utils.data import DataLoader # 데이터를 모델에 사용할 수 있도록 적재해 주는 라이브러리
from torch.utils.data import random_split
import numpy as np 
import matplotlib.pyplot as plt
```

![image](https://user-images.githubusercontent.com/106129152/209923969-efae9081-30e1-44c9-afcb-c850787c0e24.png)

```python
!nvidia-smi

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device # device(type='cuda')
```

## 1. 데이터 불러오기

```python
trainset = datasets.CIFAR10('CIFAR10_data/', download=True, train=True, transform=transforms.ToTensor())
testset = datasets.CIFAR10('CIFAR10_data/', download=True, train=False, transform=transforms.ToTensor())

trainset, validset = random_split(trainset, [40000, 10000])

print(type(trainset), len(trainset))
print(type(validset), len(validset))
print(type(testset), len(testset))
# <class 'torch.utils.data.dataset.Subset'> 40000
# <class 'torch.utils.data.dataset.Subset'> 10000
# <class 'torchvision.datasets.cifar.CIFAR10'> 10000

print(type(trainset[0][0]), type(trainset[0][1]))
# <class 'torch.Tensor'> <class 'int'>

trainset[0][0].size() # trainset[0][0].shape → channels * height * width
# torch.Size([3, 32, 32])
```

## 2. 데이터 시각화

```python
sample_img = trainset[0][0]
sample_img.size()
# torch.Size([3, 32, 32])

# 컬러 이미지를 다룰 경우에는 squeeze 할 필요 없음 
# color_sample = sample_img.permute(1, 2, 0) / numpy ndarray는 transpose
plt.imshow(sample_img.permute(1, 2, 0))
```

![image](https://user-images.githubusercontent.com/106129152/209923995-60458ebb-06fe-46e9-bd35-df547011d19d.png)

```python
labels_map = {0 : 'airplane', 1 : 'automobile', 2 : 'bird', 3 : 'cat', 4 : 'deer', 5 : 'dog', 6 : 'frog',
              7 : 'horse', 8 : 'ship', 9 : 'truck'}

figure, axes = plt.subplots(nrows=4, ncols=8, figsize=(16, 8))
axes = axes.flatten()

for i in range(32):
    rand_i = np.random.randint(0, len(trainset))
    image = trainset[rand_i][0].permute(1, 2, 0)
    axes[i].axis('off')
    axes[i].imshow(image)
    axes[i].set_title(labels_map[trainset[rand_i][1]])
```

![image](https://user-images.githubusercontent.com/106129152/209924015-2d811804-75c9-4472-ba31-0b96065389fb.png)

## 3. 데이터 적재

```python
# 배치 사이즈 16일 때는 1 epoch당 학습에 걸리는 횟수가 2500회 (훈련 데이터 40,000개 기준)
batch_size = 16 # 100 -> 16
trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True) # 훈련용
validloader = DataLoader(validset, batch_size=batch_size, shuffle=False) # 검증용
testloader = DataLoader(testset, batch_size=batch_size, shuffle=False) # 테스트용

print(type(trainloader), len(trainloader))
print(type(validloader), len(validloader))
print(type(testloader), len(testloader))
# <class 'torch.utils.data.dataloader.DataLoader'> 2500
# <class 'torch.utils.data.dataloader.DataLoader'> 625
# <class 'torch.utils.data.dataloader.DataLoader'> 625

train_iter = iter(trainloader)
images, labels = next(train_iter)
print(images.size(), labels.size())
# torch.Size([16, 3, 32, 32]) torch.Size([16])
```

## 4. 모델 생성

```python
from torch import nn # 파이토치에서 제공하는 다양한 계층(Linear layer, Convolutional Layer...)
from torch import optim # 옵티마이저 (경사하강법...)
import torch.nn.functional as F # 파이토치에서 제공하는 함수(활성화 함수...)
```

```python
class CIFAR10_CNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Sequential(
        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),
        nn.BatchNorm2d(num_features=32),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 32 x 16 x 16
    self.conv2 = nn.Sequential(
        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
        nn.BatchNorm2d(num_features=64),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 64 x 8 x 8

    self.conv3 = nn.Sequential(
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
        nn.BatchNorm2d(num_features=128),
        nn.ReLU(),
        nn.Dropout(0.4),
        nn.MaxPool2d(kernel_size=2, stride=2)
    ) # 128 x 4 x 4

    self.fc1 = nn.Linear(in_features=128*4*4, out_features=128)
    self.bn1 = nn.BatchNorm1d(num_features=128)
    self.fc2 = nn.Linear(in_features=128, out_features=10)

  def forward(self, x):
    x = self.conv1(x) # 32 x 16 x 16
    x = self.conv2(x) # 64 x 8 x 8
    x = self.conv3(x) # 128 x 4 x 4
    x = x.view(-1, 128*4*4) # flatten
    x = self.fc1(x) 
    x = self.bn1(x)
    x = F.dropout(x, 0.5)
    x = self.fc2(x)
    return x
```

```python
model = CIFAR10_CNN()
model.to(device)
model
```

![image](https://user-images.githubusercontent.com/106129152/209924051-6a70e062-f606-4c5a-b151-1cc5f85e3c39.png)

```python
for name, parameter in model.named_parameters():
  print(name, parameter.size())
```

![image](https://user-images.githubusercontent.com/106129152/209924065-0baff747-9926-4fc7-8a99-1ada7f64a402.png)

```python
from torchsummary import summary
summary(model, (3, 32, 32)) # (channel, input_size)
```

![image](https://user-images.githubusercontent.com/106129152/209924078-cfe9da2d-94df-437f-b7d2-8d1fd1eea6e8.png)

## 5. 모델 컴파일

```python
learning_rate = 0.001 
# 손실함수
criterion = nn.CrossEntropyLoss()
# 옵티마이저(경사하강법, 최적화 함수)
#optimizer = optim.SGD(model.parameters(), lr = learning_rate)
# 규제의 강도 설정 weight_decay
# optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=0.001)
optimizer = optim.Adam(model.parameters(), lr = learning_rate)

# Learning Rate Schedule
#monitoring 하고 있는 값(valid_loss)이 patience 기간동안(onPlateau) 줄어들지 않을때 lr에 factor(0.1)를 곱해준다.
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)
```

## 6. 모델 훈련

```python
def validation(model, validloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  valid_accuracy = 0
  valid_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28
      
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      valid_accuracy += accuracy
      valid_loss += loss.item() # tensor 값을 꺼내옴
    

  return valid_loss, valid_accuracy # validloader 전체 대한 총 loss, 총 accuracy
```

```python
from torch.utils.tensorboard import SummaryWriter
writer  = SummaryWriter()

def train(model, epochs, criterion, optimizer):
  steps = 0
  min_loss = 10000
  max_accuracy = 0

  trigger = 0
  patience = 10 # for Early stopping

  # 1 에폭(epoch)당 반복수
  #steps_per_epoch = len(trainset)/batch_size # 2500 iterations
  steps_per_epoch = len(trainloader) # 2500 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
      steps += 1
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력 데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      outputs = model.forward(images) # 예측
      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

      # 3. 역방향(Backward) 오차(Gradient) 전파
      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
      loss.backward()

      # 4. 경사하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0: # step : 2500, .... (epoch 마다)
        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad 시각화를 위한 로그 이벤트 등록
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
        
        # Best model 저장
        # option 1
        # if valid_loss < min_loss:
        #   min_loss = valid_loss
        #   torch.save(model.state_dict(), 'best_checkpoint.pth')

        # option 2
        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping (조기 종료)
        if valid_loss > min_loss:
          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가
          print('trigger : ', trigger )
          if trigger > patience:
            print('Early Stopping!!!')
            print('Traning step is finished!!')
            writer.flush()  
            return   
        else:
          trigger = 0
          min_loss = valid_loss

        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)

  writer.flush()

epochs=50
train(model, epochs, criterion, optimizer)
```

![image](https://user-images.githubusercontent.com/106129152/209924097-6b6e858c-fa3b-4820-b603-7da68adf0a03.png)

![image](https://user-images.githubusercontent.com/106129152/209924112-6def7dcb-b5e3-4cd2-a324-099f0c6fd041.png)

## 7. 모델 예측

```python
test_iter = iter(testloader)
images, labels = next(test_iter)
images, labels = images.to(device), labels.to(device)
print(images.size(), labels.size())
# torch.Size([16, 3, 32, 32]) torch.Size([16])

rnd_idx = 10
images[rnd_idx:rnd_idx+1].shape, labels[rnd_idx:rnd_idx+1] # 1, 3, 32, 32
# (torch.Size([1, 3, 32, 32]), tensor([0], device='cuda:0'))
```

```python
# not Flatten!
# flattend_img = images[rnd_idx].view(1, 784)
img = images[rnd_idx:rnd_idx+1]
with torch.no_grad():
  model.eval() # 배치 정규화가 들어가면서 전방향 연산이 학습시와는 달라지므로 반드시 eval() 넣어야 함
  logit = model.forward(img)

pred = logit.max(dim=1)[1]
pred == labels[rnd_idx]
# tensor([True], device='cuda:0')

img = img.cpu()
plt.imshow(img[0].permute(1, 2, 0))
```

![image](https://user-images.githubusercontent.com/106129152/209924128-cf090ec1-f601-4625-8d30-53879b5edeb0.png)

## 8. 모델 평가

```python
def evaluation(model, testloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  test_accuracy = 0
  test_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    model.eval()
    for images, labels in testloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) (10000/16)번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!
      # images.resize_(images.size()[0], 784) # 16, 3, 32, 32

      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()
      
      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      test_accuracy += accuracy.item()
      test_loss += loss.item() # tensor 값을 꺼내옴
    

  print('Test Loss : ', test_loss/len(testloader))
  print('Test Accuracy : ', test_accuracy/len(testloader))
```

```python
evaluation(model, testloader, criterion)
# Test Loss :  0.5642028164505959
# Test Accuracy :  0.809
```

## 9. 모델 저장

```python
torch.save(model.state_dict(), 'last_checkpoint.pth')
last_state_dict = torch.load('last_checkpoint.pth')

last_model = CIFAR10_CNN()
last_model.to(device)
last_model.load_state_dict(last_state_dict)
evaluation(last_model, testloader, criterion)
# Test Loss :  0.562225353527069
# Test Accuracy :  0.8102

best_state_dict = torch.load('best_checkpoint.pth')
best_model = CIFAR10_CNN()
best_model.to(device)
best_model.load_state_dict(best_state_dict)
evaluation(best_model, testloader, criterion)
# Test Loss :  0.5750618230223655
# Test Accuracy :  0.8092
```

# CIFAR10 (2) - AlexNet

→ [AlexNet이란?](https://velog.io/@ss-hj/AlexNet%EC%9D%B4%EB%9E%80)

(이것 역시 자세한 과정은 구글 코랩 파일 확인)

![image](https://user-images.githubusercontent.com/106129152/209924155-2ed3301a-4237-4e76-923d-db0a95b72a5f.png)

![image](https://user-images.githubusercontent.com/106129152/209924167-406d889b-7f11-4cc6-a56a-9fe46f2e5322.png)

```python
class AlexNet(nn.Module):
  def __init__(self):
    super().__init__()
    self.features = nn.Sequential(
        # 1st block
        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=1),
        nn.BatchNorm2d(96),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2), # 96 x 16 x 16
        # 2nd block
        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, padding=1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2), # 256 x 8 x 8
        # 3rd block
        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1), nn.BatchNorm2d(384), nn.ReLU(),
        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1), nn.BatchNorm2d(384), nn.ReLU(),
        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2) # 256 x 4 x 4 
    )

    self.classifier = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(in_features=256*4*4, out_features=1024), 
        nn.BatchNorm1d(1024),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(in_features=1024, out_features=512), 
        nn.BatchNorm1d(512),
        nn.ReLU(),
        nn.Linear(in_features=512, out_features=10)    
    )
  
  def forward(self, x):
    x = self.features(x)
    x = x.view(-1, 256*4*4)  # flatten
    x = self.classifier(x)
    return x
```

```python
model = AlexNet()
model.to(device)
model
```

![image](https://user-images.githubusercontent.com/106129152/209924181-8f80427e-a09c-49cf-87ba-2462c51aeb0d.png)

```python
for name, parameter in model.named_parameters():
  print(name, parameter.size())
```

![image](https://user-images.githubusercontent.com/106129152/209924198-f6fcc4ba-d508-47b0-bf77-31c2366daa99.png)

```python
from torchsummary import summary
summary(model, (3, 32, 32)) # (channel, input_size)
```

![image](https://user-images.githubusercontent.com/106129152/209924212-ee4cc369-1e87-49b9-b1e7-acf2d490946e.png)

```python
learning_rate = 0.001
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = learning_rate)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)

def validation(model, validloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  valid_accuracy = 0
  valid_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28
      
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      valid_accuracy += accuracy
      valid_loss += loss.item() # tensor 값을 꺼내옴
    

  return valid_loss, valid_accuracy # validloader 전체 대한 총 loss, 총 accuracy
```

```python
def train(model, epochs, criterion, optimizer):
  steps = 0
  min_loss = 10000
  max_accuracy = 0

  trigger = 0
  patience = 10 # for Early stopping

  # 1 에폭(epoch)당 반복수
  #steps_per_epoch = len(trainset)/batch_size # 2500 iterations
  steps_per_epoch = len(trainloader) # 2500 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
      steps += 1
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력 데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      outputs = model.forward(images) # 예측
      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

      # 3. 역방향(Backward) 오차(Gradient) 전파
      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
      loss.backward()

      # 4. 경사하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0: # step : 2500, .... (epoch 마다)
        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad 시각화를 위한 로그 이벤트 등록
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
        
        # Best model 저장
        # option 1
        # if valid_loss < min_loss:
        #   min_loss = valid_loss
        #   torch.save(model.state_dict(), 'best_checkpoint.pth')

        # option 2
        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping (조기 종료)
        if valid_loss > min_loss:
          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가
          print('trigger : ', trigger )
          if trigger > patience:
            print('Early Stopping!!!')
            print('Traning step is finished!!')
            writer.flush()  
            return   
        else:
          trigger = 0
          min_loss = valid_loss

        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)

  writer.flush()

epochs=55
train(model, epochs, criterion, optimizer)
```

![image](https://user-images.githubusercontent.com/106129152/209924238-214d4622-9a53-41b2-9103-7c27a6904267.png)

![image](https://user-images.githubusercontent.com/106129152/209924255-7dbbe902-0c44-415f-a49e-5e94fa02a1a9.png)

```python
evaluation(model, testloader, criterion)
# Test Loss :  0.5823295894026757
# Test Accuracy :  0.8713
```

# **Cat and Dog Classifier** (1) - AlexNet

```python
import torch # 파이토치 기본 라이브러리 
import torchvision # 이미지 관련 된 파이토치 라이브러리
from torchvision import datasets # 토치비전에서 제공하는 데이터셋
from torchvision import transforms # 이미지 전처리 기능들을 제공하는 라이브러리
from torch.utils.data import DataLoader # 데이터를 모델에 사용할 수 있도록 적재해 주는 라이브러리
from torch.utils.data import random_split
import numpy as np 
import matplotlib.pyplot as plt
```

![image](https://user-images.githubusercontent.com/106129152/209924274-74e9dac6-2c5e-4d79-b5f8-583b2efbc6aa.png)

## 0. 데이터 다운로드

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device # device(type='cuda')

# option 1 : 직접 파일 업로드
from google.colab import files
files.upload()

# option 2 : 구글 드라이브에서 업로드
from google.colab import drive
drive.mount('/content/drive')
!cp '/content/drive/MyDrive/Colab Notebooks/CNN/kaggle_catanddog.zip' './'
!unzip kaggle_catanddog.zip -d catanddog/
data_dir = './catanddog'
```

## 1. 데이터 불러오기

데이터셋의 이미지 크기가 다 달라서 미리 resize를 함!

```python
# 이미지 리사이즈와 텐서로 변경
transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()])

# 이 방법은 데이터 세트가 잘 분리, 정리된 경우
trainset = datasets.ImageFolder(root= data_dir + '/training_set/training_set', transform=transform)
testset = datasets.ImageFolder(root= data_dir + '/test_set/test_set', transform=transform)

trainset, validset = random_split(trainset, [7000, 1005])
print(type(trainset), len(trainset))
print(type(validset), len(validset))
print(type(testset), len(testset))
# <class 'torch.utils.data.dataset.Subset'> 7000
# <class 'torch.utils.data.dataset.Subset'> 1005
# <class 'torchvision.datasets.folder.ImageFolder'> 2023

print(type(trainset[0][0]), type(trainset[0][1]))
# <class 'torch.Tensor'> <class 'int'>

# channels * height * width 
trainset[0][0].size(), trainset[0][1]
# (torch.Size([3, 224, 224]), 1)
```

## 2. 데이터 시각화

- **tensor를 matplotlib에서 표시**
    
    ```python
    # 1번 샘플
    sample_img = trainset[1][0]
    sample_img.size() # torch.Size([3, 224, 224])
    
    plt.imshow(sample_img.permute(1, 2, 0))
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/209924299-a2e55157-6f82-46d1-8b52-f1aedd139112.png)
    
- **numpy로 변환한 뒤 matplotlib으로 표시**
    
    ```python
    sample_img.size() # torch.Size([3, 224, 224])
    
    numpy_sample = sample_img.numpy()
    numpy_sample.shape # (3, 224, 224)
    
    type(numpy_sample) # numpy.ndarray
    
    plt.imshow(numpy_sample.transpose(1, 2, 0)) # 차원 순서 변경할 때 tensor는 permute, ndarray는 transpose
    ```
    
    ![image](https://user-images.githubusercontent.com/106129152/209924301-9d978dea-df87-48a7-8c1b-949fc62869d8.png)
    

```python
figure, axes = plt.subplots(nrows=1, ncols=8, figsize=(22, 6))
for i in range(8):
  axes[i].imshow(trainset[i][0].permute(1, 2, 0))
  axes[i].axis('off')
  axes[i].set_title(trainset[i][1])
```

![image](https://user-images.githubusercontent.com/106129152/209924313-b319b573-8ab9-4533-8654-82c52f658d16.png)

```python
labels_map = {0 : 'cat', 1 : 'dog'}   

figure, axes = plt.subplots(nrows=4, ncols=8, figsize=(16, 8))
axes = axes.flatten()

for i in range(32):
    rand_i = np.random.randint(0, len(trainset))
    image = trainset[rand_i][0].permute(1, 2, 0)
    axes[i].axis('off')
    axes[i].imshow(image)
    axes[i].set_title(labels_map[trainset[rand_i][1]])
```

![image](https://user-images.githubusercontent.com/106129152/209924332-81331bcf-d650-4254-ad01-f39634feb3f3.png)

## 3. 데이터 적재

```python
batch_size = 16 # 100 -> 16
trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True) # 훈련용
validloader = DataLoader(validset, batch_size=batch_size, shuffle=False) # 검증용
testloader = DataLoader(testset, batch_size=batch_size, shuffle=False) # 테스트용

print(type(trainloader), len(trainloader))
print(type(validloader), len(validloader))
print(type(testloader), len(testloader))
# <class 'torch.utils.data.dataloader.DataLoader'> 438
# <class 'torch.utils.data.dataloader.DataLoader'> 63
# <class 'torch.utils.data.dataloader.DataLoader'> 127

train_iter = iter(trainloader)
images, labels = next(train_iter)
print(images.size(), labels.size())
# torch.Size([16, 3, 224, 224]) torch.Size([16])

gird_img = torchvision.utils.make_grid(images)
plt.figure(figsize=(10, 100))
plt.imshow(gird_img.permute(1, 2, 0))
```

![image](https://user-images.githubusercontent.com/106129152/209924352-16ce075b-aa4b-48f0-b661-a08c48d384b3.png)

## 4. 모델 생성

```python
from torch import nn # 파이토치에서 제공하는 다양한 계층(Linear layer, Convolutional Layer...)
from torch import optim # 옵티마이저 (경사하강법...)
import torch.nn.functional as F # 파이토치에서 제공하는 함수(활성화 함수...)
```

```python
class AlexNet(nn.Module):
  def __init__(self):
    super().__init__()
    self.features = nn.Sequential(
        # 1st block
        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=1),
        nn.BatchNorm2d(96),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2), # 96 x 112 x 112
        # 2nd block
        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, padding=1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2), # 256 x 56 x 56
        # 3rd block
        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1), nn.BatchNorm2d(384), nn.ReLU(),
        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1), nn.BatchNorm2d(384), nn.ReLU(),
        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2) # 256 x 28 x 28 
    )

    self.classifier = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(in_features=256*28*28, out_features=1024), 
        nn.BatchNorm1d(1024),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(in_features=1024, out_features=512), 
        nn.BatchNorm1d(512),
        nn.ReLU(),
        nn.Linear(in_features=512, out_features=2)  # cat과 dog 두 개의 특성만 있으므로 out_features=2   
    )
  
  def forward(self, x):
    x = self.features(x)
    x = x.view(-1, 256*28*28)  # flatten
    x = self.classifier(x)
    return x
```

```python
model = AlexNet()
model.to(device)
model
```

![image](https://user-images.githubusercontent.com/106129152/209924372-7cf99aae-38dc-4749-ba70-dc3638bfb6d6.png)

```python
for name, parameter in model.named_parameters():
  print(name, parameter.size())
```

![image](https://user-images.githubusercontent.com/106129152/209924387-52b3e5c6-6b6c-41c9-8b73-5dbe0c1f449b.png)

```python
from torchsummary import summary
summary(model, (3, 224, 224)) # (channel, input_size)
```

![image](https://user-images.githubusercontent.com/106129152/209924402-d22bd7a7-8a2b-4b5d-8593-2fd065ccf3bf.png)

## 5. 모델 컴파일

```python
learning_rate = 0.001 
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = learning_rate)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)
```

## 6. 모델 훈련

```python
def validation(model, validloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  valid_accuracy = 0
  valid_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in validloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 10000/16번을 iterations
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28
      
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      valid_accuracy += accuracy
      valid_loss += loss.item() # tensor 값을 꺼내옴
    

  return valid_loss, valid_accuracy # validloader 전체 대한 총 loss, 총 accuracy
```

```python
from torch.utils.tensorboard import SummaryWriter
writer  = SummaryWriter()

def train(model, epochs, criterion, optimizer):
  steps = 0
  min_loss = 10000
  max_accuracy = 0

  trigger = 0
  patience = 13 # for Early stopping

  # 1 에폭(epoch)당 반복수
  #steps_per_epoch = len(trainset)/batch_size # 2500 iterations
  steps_per_epoch = len(trainloader) # 2500 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
      steps += 1
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력 데이터 준비
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      outputs = model.forward(images) # 예측
      loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

      # 3. 역방향(Backward) 오차(Gradient) 전파
      optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
      loss.backward()

      # 4. 경사하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0: # step : 2500, .... (epoch 마다)
        model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad 시각화를 위한 로그 이벤트 등록
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
        
        # Best model 저장
        # option 1
        # if valid_loss < min_loss:
        #   min_loss = valid_loss
        #   torch.save(model.state_dict(), 'best_checkpoint.pth')

        # option 2
        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping (조기 종료)
        if valid_loss > min_loss:
          trigger += 1 # valid loss가 min_loss 를 갱신하지 못할때마다 증가
          print('trigger : ', trigger )
          if trigger > patience:
            print('Early Stopping!!!')
            print('Traning step is finished!!')
            writer.flush()  
            return   
        else:
          trigger = 0
          min_loss = valid_loss

        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)

  writer.flush()

epochs=55
train(model, epochs, criterion, optimizer)
```

![image](https://user-images.githubusercontent.com/106129152/209924435-24ad7229-0a06-4836-9a7e-2254c8faea50.png)

![image](https://user-images.githubusercontent.com/106129152/209924451-1e1de032-fbaf-49a6-8b8b-54c17bae641e.png)

상당히 많은 파라미터 때문인지 과적합이 눈에 띄게 나타났다(…)

## 7. 모델 예측

```python
test_iter = iter(testloader)
images, labels = next(test_iter)
images, labels = images.to(device), labels.to(device)
print(images.size(), labels.size()) # torch.Size([16, 3, 224, 224]) torch.Size([16])

rnd_idx = 10
images[rnd_idx:rnd_idx+1].shape, labels[rnd_idx:rnd_idx+1] # 1, 3, 32, 32
# (torch.Size([1, 3, 224, 224]), tensor([0], device='cuda:0'))

# not Flatten!
# flattend_img = images[rnd_idx].view(1, 784)
img = images[rnd_idx:rnd_idx+1]
with torch.no_grad():
  model.eval() # 배치 정규화가 들어가면서 전방향 연산이 학습시와는 달라지므로 반드시 eval() 넣어야 함
  logit = model.forward(img)

pred = logit.max(dim=1)[1]
pred == labels[rnd_idx] # tensor([True], device='cuda:0')

pred, labels[rnd_idx]
# (tensor([0], device='cuda:0'), tensor(0, device='cuda:0'))

img = img.cpu()
plt.imshow(img[0].permute(1, 2, 0))
```

![image](https://user-images.githubusercontent.com/106129152/209924475-95c8d20a-9398-4cbc-bf30-4482a860a243.png)

## 8. 모델 평가

```python
def evaluation(model, testloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  test_accuracy = 0
  test_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    model.eval()
    for images, labels in testloader: 
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력데이터 준비
      # not Flatten!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()
      
      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      test_accuracy += accuracy.item()
      test_loss += loss.item() # tensor 값을 꺼내옴
    

  print('Test Loss : ', test_loss/len(testloader))
  print('Test Accuracy : ', test_accuracy/len(testloader))

evaluation(model, testloader, criterion)
# Test Loss :  0.6192885394992791
# Test Accuracy :  0.8063132734749261
```

## 9. 모델 저장

```python
torch.save(model.state_dict(), 'last_checkpoint.pth')
last_state_dict = torch.load('last_checkpoint.pth')
last_model = AlexNet()
last_model.to(device)
last_model.load_state_dict(last_state_dict)
evaluation(last_model, testloader, criterion)
# Test Loss :  0.6192885394992791
# Test Accuracy :  0.8063132734749261

best_state_dict = torch.load('best_checkpoint.pth')
best_model = AlexNet()
best_model.to(device)
best_model.load_state_dict(best_state_dict)
evaluation(best_model, testloader, criterion)
# Test Loss :  0.5607036457756372
# Test Accuracy :  0.8028683915851623
```
