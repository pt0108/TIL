> 부트캠프 11주차 2022년 12월 27일

# Fashion MNIST in Pytorch

## (1) 텐서보드, 옵티마이저

```python
import torch # 파이토치 기본 라이브러리 
import torchvision # 이미지 관련 된 파이토치 라이브러리
from torchvision import datasets # 토치비전에서 제공하는 데이터셋
from torchvision import transforms # 이미지 전처리 기능들을 제공하는 라이브러리
from torch.utils.data import DataLoader # 데이터를 모델에 사용할 수 있도록 적재해 주는 라이브러리
from torch.utils.data import random_split
import numpy as np 
import matplotlib.pyplot as plt
```

### 1. 데이터 불러오기

```python
trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transforms.ToTensor())
testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transforms.ToTensor())

trainset, validset = random_split(trainset, [50000, 10000])
```

```python
print(type(trainset), len(trainset))
print(type(validset), len(validset))
print(type(testset), len(testset))
# <class 'torch.utils.data.dataset.Subset'> 50000
# <class 'torch.utils.data.dataset.Subset'> 10000
# <class 'torchvision.datasets.mnist.FashionMNIST'> 10000

# trainset[0][0] # tensor로 변환된 이미지 데이터
# trainset[0][1] # 이미지 데이터의 라벨(정답)
print(type(trainset[0][0]), type(trainset[0][1]))
# <class 'torch.Tensor'> <class 'int'>

trainset[0][0].size() # trainset[0][0].shape
# torch.Size([1, 28, 28])
```

### 2. 데이터 시각화

**tensor ~ matplotlib**

```python
sample_img = trainset[0][0]
sample_img.size() # torch.Size([1, 28, 28])

sample_img[0].size() # torch.Size([28, 28])

plt.imshow(sample_img[0], cmap='gray')
```

![image](https://user-images.githubusercontent.com/106129152/209635411-3dd099ae-9299-48fc-96b2-d18081197b1e.png)

**numpy ~ matplotlib**

```python
sample_img.size() # torch.Size([1, 28, 28])

numpy_sample = sample_img.numpy()
numpy_sample.shape # (1, 28, 28)
 
type(numpy_sample) # numpy.ndarray

plt.imshow(numpy_sample[0], cmap='gray')
```

![image](https://user-images.githubusercontent.com/106129152/209635418-2a885c84-04b5-407d-aee8-6c398c125f2f.png)

**tensor 자체 차원 색인**

```python
sample_img.size() # torch.Size([1, 28, 28])

sample_tensor = sample_img.permute(1, 2, 0).squeeze(axis=2)
plt.imshow(sample_tensor, cmap='gray')
```

![image](https://user-images.githubusercontent.com/106129152/209635428-c9cb8bbe-1c9b-4bff-83d7-905eb0c36ab1.png)

```python
labels_map = {0 : 'T-shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt', 
              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}

figure, axes = plt.subplots(nrows=4, ncols=8, figsize=(16, 8))
axes = axes.flatten()

for i in range(32):
    rand_i = np.random.randint(0, len(trainset))
    image = trainset[rand_i][0][0]
    axes[i].axis('off')
    axes[i].imshow(image, cmap='gray')
    axes[i].set_title(labels_map[trainset[rand_i][1]])
```

![image](https://user-images.githubusercontent.com/106129152/209635456-277cdb67-b4ff-4978-bf9e-3944cf6ddb3a.png)

### 3. 데이터 적재

```python
batch_size = 100
trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True) # 훈련용
validloader = DataLoader(validset, batch_size=batch_size, shuffle=False) # 검증용
testloader = DataLoader(testset, batch_size=batch_size, shuffle=False) # 테스트용
```

```python
print(type(trainloader), len(trainloader))
print(type(validloader), len(validloader))
print(type(testloader), len(testloader))
# <class 'torch.utils.data.dataloader.DataLoader'> 500
# <class 'torch.utils.data.dataloader.DataLoader'> 100
# <class 'torch.utils.data.dataloader.DataLoader'> 100

train_iter = iter(trainloader)
images, labels = next(train_iter)
print(images.size(), labels.size())
# torch.Size([100, 1, 28, 28]) torch.Size([100])
```

### 4. 모델 생성

```python
from torch import nn # 파이토치에서 제공하는 다양한 계층(Linear layer, Convolutional Layer...)
from torch import optim # 옵티마이저 (경사하강법...)
import torch.nn.functional as F # 파이토치에서 제공하는 함수(활성화 함수...)
```

```python
class FMNIST_DNN(nn.Module):
  def __init__(self):
    super().__init__()
    # 계층 정의하기 784(input), 20(hidden), 10(output)
    # fully connected layer(dense lyaer, affine layer) : np.dot(x, w) + b
    self.fc1 = nn.Linear(in_features=784, out_features=128) 
    self.fc2 = nn.Linear(in_features=128, out_features=64)
    self.fc3 = nn.Linear(in_features=64, out_features=10)
              

  def forward(self, x):
    x = self.fc1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = F.relu(x)
    x = self.fc3(x)
    # x = F.softmax(x)
    return x
```

```python
model = FMNIST_DNN()
model
# FMNIST_DNN(
#   (fc1): Linear(in_features=784, out_features=128, bias=True)
#   (fc2): Linear(in_features=128, out_features=64, bias=True)
#   (fc3): Linear(in_features=64, out_features=10, bias=True)
# )

for name, parameter in model.named_parameters():
  print(name, parameter.size())
# fc1.weight torch.Size([128, 784])
# fc1.bias torch.Size([128])
# fc2.weight torch.Size([64, 128])
# fc2.bias torch.Size([64])
# fc3.weight torch.Size([10, 64])
# fc3.bias torch.Size([10])
```

```python
from torchsummary import summary
summary(model, (1, 784)) # (channle, input_size)
```

![image](https://user-images.githubusercontent.com/106129152/209635486-137844c8-90bd-42df-91cc-4e7a3e024446.png)

### 5. 모델 컴파일(손실 함수, 옵티마이저 선택)

```python
learning_rate = 0.001 
# 손실함수
criterion = nn.CrossEntropyLoss()
# 옵티마이저(경사하강법, 최적화 함수)
# optimizer = optim.SGD(model.parameters(), lr = learning_rate)
optimizer = optim.Adam(model.parameters(), lr = learning_rate)
```

이번에는 SGD가 아닌 Adam을 사용. 

learning_rate도 0.1이 아닌 Adam 의 디폴트값 0.001로 변경하였다.

### 6. 모델 훈련(with 검증)

```python
def validation(model, validloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  valid_accuracy = 0
  valid_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in validloader: # 10000개의 데이터에 대해 100개씩(미니배치 사이즈) 100번을 iterations
      # 1. 입력데이터 준비
      images.resize_(images.size()[0], 784) # 100, 1, 28, 28
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 100개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 100개에 대한 loss
      
      valid_accuracy += accuracy
      valid_loss += loss.item() # tensor 값을 꺼내옴
    

  return valid_loss, valid_accuracy # 100세트 전체 대한 총 loss, 총 accuracy
```

→ [파이토치에서 텐서보드 사용하기](https://tutorials.pytorch.kr/recipes/recipes/tensorboard_with_pytorch.html) 

```python
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter()
```

```python
epochs = 17 # 17 epoch 이후에 valid_loss 가 줄지 않아 35->17로 변경
steps = 0

# 1 에폭(epoch)당 반복수
#steps_per_epoch = len(trainset)/batch_size # 500 iterations
steps_per_epoch = len(trainloader) # 500 iterations

for epoch in range(epochs):
  model.train()
  train_loss = 0
  for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 100개씩을 가져와 images, labels에 준비
    steps += 1
    # 1. 입력 데이터 준비
    images.resize_(images.size()[0], 784) # 100, 1, 28, 28

    # 2. 전방향(Forward) 예측 
    outputs = model.forward(images) # 예측
    loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

    # 3. 역방향(Backward) 오차(Gradient) 전파
    optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
    loss.backward()

    # 4. 경사하강법으로 모델 파라미터 업데이트
    optimizer.step() # W <- W -lr*Gradient

    train_loss += loss.item()
    if (steps % steps_per_epoch) == 0: # step : 500, 1000, 1500 (epoch 마다)
      model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
      valid_loss, valid_accuracy = validation(model, validloader, criterion)

      # tensorboad 시각화를 위한 로그 이벤트 등록
      writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
      writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
      writer.add_scalars("Loss/train and valid", 
                         {'train' : train_loss/len(trainloader),
                         'valid' : valid_loss/len(validloader)}, epoch)
      
      writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

      print('Epoch : {}/{}.....'.format(epoch+1, epochs),
            'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
            'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
            'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
      train_loss = 0
      model.train()
      
writer.flush()
```

![image](https://user-images.githubusercontent.com/106129152/209635534-75d418b2-d8d6-4d7f-a526-e5856f7a8789.png)

```python
%load_ext tensorboard
%tensorboard --logdir=runs
```

여기서 주황색 그래프는 SGD를 사용한 결과,

**하늘색 그래프는 Adam**을 사용한 결과이다. (+ 분홍색, 초록색)

![image](https://user-images.githubusercontent.com/106129152/209635566-7f16e60a-83a2-4566-8b73-b217b5310351.png)
![image](https://user-images.githubusercontent.com/106129152/209635594-19330986-34aa-4923-8fc9-da7b9837c0ad.png)

```python
writer.close()
```

텐서보드를 통해 확인할 수 있던 것은 모델의 학습 과정에서 **과적합**이 일어났다는 것!

![image](https://user-images.githubusercontent.com/106129152/209635619-4cad6ef3-c59a-483a-afd0-f06bed2bd3ce.png)

### 7. 모델 예측

```python
test_iter = iter(testloader)
images, labels = next(test_iter)
print(images.size(), labels.size())
# torch.Size([100, 1, 28, 28]) torch.Size([100])

rnd_idx = 10
images[rnd_idx].shape, labels[rnd_idx] # 1, 28, 28
# (torch.Size([1, 28, 28]), tensor(4))

flattend_img = images[rnd_idx].view(1, 784)
with torch.no_grad():
  logit = model.forward(flattend_img)

pred = logit.max(dim=1)[1]
pred == labels[rnd_idx]
# tensor([True])

plt.imshow(images[rnd_idx][0], cmap='gray')
```

![image](https://user-images.githubusercontent.com/106129152/209635644-e86de404-0348-4c1d-a3c7-b91446ed3a42.png)

### 8. 모델 평가

```python
def evaluation(model, testloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  test_accuracy = 0
  test_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    for images, labels in testloader: # 10000개의 데이터에 대해 100개씩(미니배치 사이즈) 100번을 iterations
      # 1. 입력데이터 준비
      images.resize_(images.size()[0], 784) # 100, 1, 28, 28
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 100개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 100개에 대한 loss
      
      test_accuracy += accuracy.item()
      test_loss += loss.item() # tensor 값을 꺼내옴
    

  print('Test Loss : ', test_loss/len(testloader))
  print('Test Accuracy : ', test_accuracy/len(testloader))
```

```python
evaluation(model, testloader, criterion)
# Test Loss :  0.3584479506313801
# Test Accuracy :  0.8768999999761582
```

### ↻ 배치 사이즈를 16으로 변경했을 때

배치 사이즈는 중요한 하이퍼 파라미터, 16 이하로 사용하는 것이 성능에 좋다고 알려져 있음.

배치 사이즈가 크다 → 실제 Loss, Gradient, Weight를 구하는 데 참여하는 데이터가 많다는 뜻
배치 사이즈가 작다 → 실제 Loss, Gradient, Weight를 구하는 데 참여하는 데이터가 작다는 뜻

배치 사이즈가 작음 → 실제 모델 학습을 하는 데 한번도 보지 못한 신선한 데이터가 제공
배치 사이즈가 큼 → 학습에 참여했던 데이터가 다시 뽑힐 확률이 크고, 1 epoch을 학습하는 데에도 시작이 적게 걸림

배치 사이즈가 100일 때 : 1 epoch당 학습에 걸린 횟수가 500회 (훈련 데이터 5만개 기준)
배치 사이즈가 16일 때 : 1 epoch당 학습에 걸린 횟수가 3125회 (훈련 데이터 5만개 기준)

```python
batch_size = 16 # 100 → 16
trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True) # 훈련용
validloader = DataLoader(validset, batch_size=batch_size, shuffle=False) # 검증용
testloader = DataLoader(testset, batch_size=batch_size, shuffle=False) # 테스트용
```

위와 같이 배치 사이즈만 16으로 수정하고 이외의 코드는 그대로 진행.

학습 과정은 아래와 같이 나왔다.

![image](https://user-images.githubusercontent.com/106129152/209635693-e6aa8b21-9872-4768-8ae3-1575b33694bf.png)

![image](https://user-images.githubusercontent.com/106129152/209635720-ef64788e-1d9c-44d5-847e-00bc2f2f60ef.png)

![image](https://user-images.githubusercontent.com/106129152/209635738-c455f0fb-55af-41f3-8994-042bd69f04ad.png)

![image](https://user-images.githubusercontent.com/106129152/209635760-82bd65f2-4dcc-4e36-b89a-fd3c3e02f0a6.png)

모델의 성능은 조금 더 높아진 것을 확인할 수 있었다.

다만, 과적합이 일어나는 시기가 더 앞당겨졌다.

(이는 epoch 수를 줄이거나, 규제를 가하는 것으로 해결해야 함!)

## (2) 가중치 초기화, 배치 정규화

### 가중치 초기화

초기값을 0으로 하면 **오차 역전파법에서 모든 가중치의 값이 똑같이 갱신**된다.

가중치들이 같은 초기값에서 시작하고, 갱신을 거쳐도 여전히 같은 값을 유지.

**→ 가중치를 여러 개 갖는 의미가 사라짐! 그러므로 초기값을 무작위로 설정**해야 한다.

- 평균이 0, 표준편차가 1인 정규분포를 따르는 가중치 값들로 초기화
    
    데이터가 0과 1에 치우쳐 분포하게 되면 역전파의 기울기 값이 점점 작아지다 사라진다. 
    
    이것이 **기울기 소실(gradient vanishing)**이라 알려진 문제.
    
    → 층을 깊게 하는 딥러닝에서 기울기 손실은 심각한 문제!
    

- 평균이 0, 표준편차가 0.01인 정규분포를 따르는 가중치 값들로 초기화
    
    sigmoid가 활성화 함수로 쓰인 layer들을 통과할수록 그 출력 값이 0.5에 몰림.
    
    활성화 값들이 치우치면 다수의 뉴런이 거의 같은 값을 출력해 뉴런 1개와 다를게 없음.
    
    → **표현력을 제한**한다는 관점에서 문제.
    

이 문제들을 해결할 방법으로 활성화 함수가 **선형일 때 Xavier** 초기값, ****

**선형이 아닌 ReLU일 때** **He** 초기값 등을 사용한다.

[여기](https://mole-starseeker.tistory.com/42)에 정리가 잘 되어있다.

**가중치 초기화**

[파이토치 문서](https://pytorch.org/docs/stable/nn.init.html)

현재 디폴트 값 : [Conv](https://github.com/pytorch/pytorch/blob/9cf62a4b5d3b287442e70c0c560a8e21d8c3b189/torch/nn/modules/conv.py#L111), [Linear](https://github.com/pytorch/pytorch/blob/9cf62a4b5d3b287442e70c0c560a8e21d8c3b189/torch/nn/modules/linear.py#L168)

**가중치 초기화 시 고려할 사항**

1. 값이 충분히 작아야 한다.

2. 값이 하나로 치우쳐지면 안된다.

3. 적당한 분산으로 골고루 분포가 되어야 한다.

```python
class FMNIST_DNN(nn.Module):
  def __init__(self):
    super().__init__()
    # 계층 정의하기 784(input), 20(hidden), 10(output)
    # fully connected layer(dense lyaer, affine layer) : np.dot(x, w) + b
    self.fc1 = nn.Linear(in_features=784, out_features=128) 
    self.fc2 = nn.Linear(in_features=128, out_features=64)
    self.fc3 = nn.Linear(in_features=64, out_features=10)

    # 가중치 초기화 (He 초기화(normal))       
    nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')  
    nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='relu')   
    nn.init.kaiming_normal_(self.fc3.weight, mode='fan_out', nonlinearity='relu')   

  def forward(self, x):
    x = self.fc1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = F.relu(x)
    x = self.fc3(x)
    # x = F.softmax(x)
    return x
```

### 배치 정규화 알고리즘

배치 정규화(Batch Normalization) : 각 층의 활성화를 적당히 퍼뜨리도록 강제

학습 시 미니배치 단위로, 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화.

이 배치 정규화 계층마다 **정규화된 데이터에 고유한 확대(scale)와 이동(shift) 변환을 수행하는 것이 배치 정규화 알고리즘**이다.

1. 학습의 빠른 진행 가능

2. 초기값에 크게 의존하지 않음

3. 오버피팅 억제

```python
class FMNIST_DNN(nn.Module):
  def __init__(self):
    super().__init__()
    # 계층 정의하기 784(input), 20(hidden), 10(output)
    # fully connected layer(dense lyaer, affine layer) : np.dot(x, w) + b
    self.fc1 = nn.Linear(in_features=784, out_features=128) 
    self.bn1 = nn.BatchNorm1d(num_features=128)
    self.fc2 = nn.Linear(in_features=128, out_features=64)
    self.bn2 = nn.BatchNorm1d(num_features=64)
    self.fc3 = nn.Linear(in_features=64, out_features=10)

    # 가중치 초기화 (He 초기화(normal))       
    nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')  
    nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='relu')   
    nn.init.kaiming_normal_(self.fc3.weight, mode='fan_out', nonlinearity='relu')   

  def forward(self, x):
    x = self.fc1(x)
    x = self.bn1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = self.bn2(x)
    x = F.relu(x)
    x = self.fc3(x)
    # x = F.softmax(x)
    return x
```

모델의 학습 과정은 아래와 같다.

![image](https://user-images.githubusercontent.com/106129152/209635803-1b371cb5-95f4-4882-ac55-92f48deb3942.png)

![image](https://user-images.githubusercontent.com/106129152/209635827-2d5a718c-32c4-405b-ad37-e702157bc690.png) 

![image](https://user-images.githubusercontent.com/106129152/209635848-3c6e3594-9a3f-4e1e-a978-cc95bf54203e.png)

배치 정규화를 하면서 전방향 연산이 달라지므로 모델의 예측과 평가에는 수정이 필요!

`eval()`함수 적용

```python
flattend_img = images[rnd_idx].view(1, 784)
with torch.no_grad():
  model.eval() # 배치 정규화가 들어가면서 전방향 연산이 학습시와는 달라지므로 반드시 eval()
  logit = model.forward(flattend_img)

pred = logit.max(dim=1)[1]
pred == labels[rnd_idx]
```

```python
def evaluation(model, testloader, criterion):
  # 전방향 예측후 나온 점수(logits)의 최대값을 최종 예측으로 준비
  # 이 최종 예측과 정답을 비교
  # 전체 중 맞은 것의 개수 비율을 정확도(accuracy)로 계산
  test_accuracy = 0
  test_loss = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음
  with torch.no_grad():
    model.eval()
    for images, labels in testloader: # 10000개의 데이터에 대해 16개씩(미니배치 사이즈) 16번을 iterations
      # 1. 입력데이터 준비
      images.resize_(images.size()[0], 784) # 16, 1, 28, 28
      # 2. 전방향(Forward) 예측 
      logits = model.forward(images) # 점수 반환
      _, preds = torch.max(logits, 1) # 16개에 대한 최종 예측
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) # 16개에 대한 loss
      
      test_accuracy += accuracy.item()
      test_loss += loss.item() # tensor 값을 꺼내옴
    

  print('Test Loss : ', test_loss/len(testloader))
  print('Test Accuracy : ', test_accuracy/len(testloader))
```

![image](https://user-images.githubusercontent.com/106129152/209635892-85006b7a-c071-4a11-ac88-922485ad6dca.png)

## (3) 규제, 모델저장, 종기종료, LR Schedule

### 오버피팅

오버피팅은 **매개변수가 많고, 표현력이 높은 모델**이나 **훈련 데이터가 적은 경우**에 일어난다.

**가중치 감소(weight decay)**

→ 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과하여 오버피팅 억제

가중치의 제곱 노름(L2 norm)을 손실함수에 더해 가중치가 커지는 것을 억제.

**드롭아웃(Dropout)**

→ 모델이 복잡해지면 가중치 감소만으로는 해결이 어려움!

드롭아웃은 **훈련 때 은닉층의 뉴런을 무작위로 골라 삭제하면서 학습**하는 방법.

단, 시험 때는 모든 뉴런에 신호를 전달하고, 각 뉴런의 출력에 훈련 때 삭제 안 한 비율을 곱하여 출력함.

```python
class FMNIST_DNN(nn.Module):
  def __init__(self):
    super().__init__()
    # 계층 정의하기 784(input), 20(hidden), 10(output)
    # fully connected layer(dense lyaer, affine layer) : np.dot(x, w) + b
    self.fc1 = nn.Linear(in_features=784, out_features=128) 
    self.bn1 = nn.BatchNorm1d(num_features=128)
    self.fc2 = nn.Linear(in_features=128, out_features=64)
    self.bn2 = nn.BatchNorm1d(num_features=64)
    self.fc3 = nn.Linear(in_features=64, out_features=10)

    # 가중치 초기화 (he 초기화(normal))
    nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')
    nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='relu')
    nn.init.kaiming_normal_(self.fc3.weight, mode='fan_out', nonlinearity='relu')

  def forward(self, x):
    x = self.fc1(x)
    x = self.bn1(x)
    x = F.relu(x)
    x = F.dropout(x, 0.5)
    x = self.fc2(x)
    x = self.bn2(x)
    x = F.relu(x)
    x = F.dropout(x, 0.2)
    x = self.fc3(x)
    # x = F.softmax(x)
    return x
```

```python
learning_rate = 0.001 
# 손실함수
criterion = nn.CrossEntropyLoss()
# 옵티마이저
# 규제의 강도 설정 : weight_decay
# optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=0.001)
optimizer = optim.Adam(model.parameters(), lr = learning_rate)
```

![image](https://user-images.githubusercontent.com/106129152/209635928-486504cd-c409-4254-8335-59315e871ce4.png) 

![image](https://user-images.githubusercontent.com/106129152/209635965-f2828b33-54dc-42f3-98b3-2e8136eddc43.png)

![image](https://user-images.githubusercontent.com/106129152/209635990-782ce2e9-0e87-4bf7-8cc2-fdf4fece128d.png)

### 모델 저장

예측을 할 때마다 훈련시키는 것은 비효율적!
기존 훈련 결과에 이어서 학습을 하고자 할 때 모델을 저장한다.
→ [파이토치에서 모델 저장](https://pytorch.org/tutorials/beginner/saving_loading_models.html)

```python
model
# FMNIST_DNN(
#   (fc1): Linear(in_features=784, out_features=128, bias=True)
#   (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
#   (fc2): Linear(in_features=128, out_features=64, bias=True)
#   (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
#   (fc3): Linear(in_features=64, out_features=10, bias=True)
# )

model.state_dict().keys()
# odict_keys(['fc1.weight', 'fc1.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 
#            'bn1.running_var', 'bn1.num_batches_tracked', 'fc2.weight', 'fc2.bias', 'bn2.weight', 
#            'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 
#            'fc3.weight', 'fc3.bias'])

```

```python
torch.save(model.state_dict(), 'checkpoint.pth') # 모델 저장

state_dict = torch.load('checkpoint.pth')

loaded_model = FMNIST_DNN()
loaded_model.load_state_dict(state_dict)
# <All keys matched successfully>

evaluation(loaded_model, testloader, criterion)
# Test Loss :  0.426539586520195
# Test Accuracy :  0.8507
```

아래 코드는 모델 훈련 코드로,

중간에 best model을 저장하는 코드를 추가한 것이다.

```python
epochs = 17 # 17 epoch 이후에 valid_loss 가 줄지 않아 35->17로 변경
steps = 0
min_loss = 10000
max_accuracy = 0

# 1 에폭(epoch)당 반복수
#steps_per_epoch = len(trainset)/batch_size # 3125 iterations
steps_per_epoch = len(trainloader) # 3125 iterations

for epoch in range(epochs):
  model.train()
  train_loss = 0
  for images, labels in iter(trainloader): # 이터레이터로부터 미니배치 16개씩을 가져와 images, labels에 준비
    steps += 1
    # 1. 입력 데이터 준비
    images.resize_(images.size()[0], 784) # 16, 1, 28, 28

    # 2. 전방향(Forward) 예측 
    outputs = model.forward(images) # 예측
    loss = criterion(outputs, labels) # 예측과 결과를 통해 Cross Entropy Loss 반환

    # 3. 역방향(Backward) 오차(Gradient) 전파
    optimizer.zero_grad() # 파이토치에서 gradient가 누적되지 않게 하기 위해
    loss.backward()

    # 4. 경사하강법으로 모델 파라미터 업데이트
    optimizer.step() # W <- W -lr*Gradient

    train_loss += loss.item()
    if (steps % steps_per_epoch) == 0: # step : 3125, .... (epoch 마다)
      model.eval() # 배치 정규화, 드롭아웃이 적용될 때는 model.forward 연산이 training때와 다르므로 반드시 설정
      valid_loss, valid_accuracy = validation(model, validloader, criterion)

      # tensorboad 시각화를 위한 로그 이벤트 등록
      writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
      writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
      writer.add_scalars("Loss/train and valid",
                        {'train' : train_loss/len(trainloader),
                         'valid' : valid_loss/len(validloader)}, epoch)
      
      writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)

      print('Epoch : {}/{}.....'.format(epoch+1, epochs),
            'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
            'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
            'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
      
      # Best model 저장
      # option 1
      if valid_loss < min_loss:
        min_loss = valid_loss
        torch.save(model.state_dict(), 'best_checkpoint.pth')

      # option 2
      # if valid_accuracy > max_accuracy:
      #   max_accuracy = valid_accuracy
      #   torch.save(model.state_dict(), 'best_checkpoint.pth')

      train_loss = 0
      model.train()

writer.flush()
```
